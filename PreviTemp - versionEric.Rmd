---
title: "Previtemp"
author: "Eric PARENT à partir du texte de Jacques Bernier"
date: "4 novembre 2019"
output:
  html_notebook
---

# Chargement préalable des données et librairies nécessaires

```{r include=FALSE}
rm(list=ls())
# setwd("~/Documents/courbariaux/WORKLUC/TempEnsemblesNormal")
load("Ain@Vouglans.Rdata")
#load("Buech@Chambons.Rdata")
#load("Drac@Sautet.Rdata")
library(tidyverse)
library(tidyselect)
library(lubridate)
library(R2jags)
library(verification)
library(GGally)
library(goftest)
```


# Introduction


## Quid de la littérature?

La littérature récente de la Prévision utilise des concepts statistiques de base de façon plutôt "com. internet" en ne retenant que leurs expressions verbales "pseudo-pragmatiques précédentes" pour comparaisons, à défaut de choix judicieux et en oubliant leur profonde cohérence.
 On nous affirme la nécessité  d'une **prévision probabiliste**. Très bien mais alors la cohérence implique que cette distribution probabiliste soit une probabilité conditionnelle §[y|z]§ en fonction de l'information Z munie (éventuellement d'une distribution marginale §[z]§) d'où la nécessaire considération de la "loi du couple §[y,z]§  et de sa conséquence obligée caractérisant la seule distribution prédictive logique --valable-- soit nécessairement: 

  \[[y|z]=[y,z]/[z]=[z|y][y]/[z]\]

ce qui n'est autre que la formule de Bayes dont la prise en compte s'impose que l'on soit non bayesien classique ou bayesien (c'est à dire qui interprète les composants de l'équation differemment de l'interprétation fréquentiste et notamment la dite distribution a priori [y]). --Les classiques cohérents devraient donc être bayesiens sans le savoir--. Pour ce calcul, beaucoup d'auteurs ont utilisé le concept de "best member x(z)" et la dite "predictive distribution associée" calculée à partir des écarts absolus:

 \[|| y-x_{Z}||\] 

 Un tel calcul basé sur des erreurs brutes de prévision ne peut en aucune façon, donner même une approximation de la vraie distribution prédictive au sens probabiliste. Il y a erreur de principe et la simplicité revendiquée ne peut remplacer la rigueur ici. Faut il cacher ces erreurs commises par nombre d'auteurS?

### Autres exemples

Gneiting, avec nombre d'auteurs modernes, nous dit:"Increased recognition of the need for uncertainty quantiﬁcation ...,allow for optimal decision making.", magnifique, puis: "What is a good probabilistic forecast?"-- demande t-il et il répond "Probabilistic forecasts aim to maximize the sharpness of the predictive distributions subject to calibration".  Certes mais on n'a jamais vu une telle formalisation mise en application dans le domaine concerné. Le plus souvent on caractèrise une méthode par un CRPS continu moyen dont les valeurs sont difficiles à interpréter, sans distinguer d'ailleurs calibration et précision. En dehors de Winkler (1996), on n'a jamais reconnu l'inadaptation du CRPS, par sa symétrie, à être utilisé comme une bonne fonction de coût en --Optimal Decision Theory-- pourtant verbalement recommandée par multiples auteurs (voir Gneiting). Je ne suis pas étonné que, dans le papier d'Eric, les comparaisons de CRPS soient peu significatives à échelle annuelle entre méthodes alors que leurs qualités sont en fait ailleurs. J'essaierai de montrer que des scores discretisés comme les Brier peuvent être choisis pour de meilleures comparaisons.


# Modifications par rapport au document initial

* La première concerne la désaisonnalisation sur le couple moyenne,variance des températures calendaires (par année) que je préfererais remplacer par une désaisonnalisation classique unique: "Tt=Tclimatique + ecart" avec var(ecart) eventuellement modulée selon la saison (hiver ou été). Le problème est que les modèles d'ensembles ont, de fait, pour objet de **mieux représenter les dispersions des prévisions** des cibles et ainsi leurs résultats pourraient être influençés par cette correction a priori qui modifie la structure aléatoire de la température historique et celle des modèles d'ensembles. (voir le chunk de l'analyse des écarts).

* Cette désaisonnalisation peut retentir sur le calcul des scores. Eu égard aux difficultés de la validation des modèles de prévision par les scores CRPS, je propose d'essayer les scores discrets de BRIER symétriques et dissymétriques mis sous la forme type "Degroot et Fienberg"/
 
 $W(a,y)=W.(a-y)^{2}$
 
 (voir notre note "La Statistique et les Prévisions d'Ensemble - Je t'aime moi non plus-juin 2019" corrigée par une note annexe sur les Briers - à venir). 



# Propositions methodologiques

 Plutôt que traiter les données en "réel" en utilisant systématiquement le CRPS, je proposerais en effet de transformer les variables continues en variables vectorielles discrètes, généralisant les Bernoullis avec k classes, tel exemple: y(vecteur trimensionnel)={0,1,0}) définissant des classes recouvrant le domaine de chaque variable. L'exemple k=3, utilisé ici, est certainement trop simpliste mais, à mon avis, il illustre bien déja certaines difficultés des méthodes de post-traitements comme le CEP et celles du CRPS ordinaire.

 Les Briers (sous la forme Dg&F généralisée) peuvent être calculés en apprentissage sur 2005-2008, puis utilisés pour la validation (versions propres et assymétriques) sur la période 2011-2015 en distinguant les années. On peut faire varier à la fois k et le sur-regret W attribué à chaque classe particulière. Cette approche, en y adjoignant les comparaisons directes de fréquences d'erreurs de prévision, nous semble plus informative, en phases d'apprentissage et validation, que les calculs globaux de CRPS dits continus, ces derniers fussent ils ou non recommandés comme des dogmes intangibles par les prévisionnistes professionnels ou theoriciens du domaine en 2019.

## Retour sur le système BFS et les NQT.

 La modélisation marginale des ensembles constitue la première partie de la structure BFS appliquée aux ensembles échangeables que nous proposons. La seconde partie, modélisation prédictive, relie les "résumés de l'information marginale d'ensemble à la cible de prévision". Il y a aussi là un désaccord avec Eric sur les transformations NQT (à la mode Krzysztofowicz) normalisant les fonctions "résumés d'ensembles --> cible". On remarquera que la méthode CEP est un calcul approximatif direct, des prédictives sur les ensembles. On notera aussi que, dans l'application d'Eric, il utilise **les mêmes statistiques d'ensembles résumantes à savoir moyennes et écart types pour les 3 méthodes d'ensemble (CEP,EMOS et échangeable-BFS)**. Ceci est très important pour la comparaison entres methodes d'ensembles --utilisant la même information résumée et peut expliquer la relative déception d'Eric. Disons seulement ici que la principale qualité d'un modèle échangeable-BFS est sa parsimonie (utile en modèles adaptatifs) et difficilement apparente dans le calcul de crps globaux.

## Interprétations des latentes

 Notre discussion porte aussi sur un point de la philosophie interprétative statistique qui soutend les chunks d'Eric consacrés au modèle échangeable. Le point de départ est l'interprétation des lois:

     $Z2_{t} = dgamma(.,2g,1),     [Z1_{t}|Z2_{t}]=dnorm(.,0,(Z2_{t})^{-1})$  

a priori commme -- lois marginales de ces latentes-- . 

 Rappelons qu'on ne peut interpréter les latentes Z1t,Z2t indépendamment du modèle des X. Les priors pour chaque t ont la même structure (localement conjuguées naturelles), certes, mais elles ne sont utiles que pour modéliser l'information des membres via la NQT et Bayes à chaque t. Ce sont en premier les conditionnelles complètes [Z2t|cc] et [Z1t|Z2t,g,cc...] (aposteriori) des latentes considérées comme pivôts des prévisions qui importent dans la prévision (les Z marginaux ne sont pas des prédicteurs). Ce sont les vraies prédictives interprétés marginalement qui doivent intervenir et la NQT de la deuxième phase doit en tenir compte pour la normalisation. Ce n'est pas parce que les priors multiples dépendent d'un paramètre commun g (pour raison de parsimonie) qu'il faut leur donner une signification marginale ou préquentielle. Ce sont les moyennes et écart types d'ensemble --résumantes-- qui sont les seules informations marginales à considérer - voir ce qui suit)

 Il est donc clair que ces latentes ne sont déterminées qu'en distributions conditionnelles à information donnée. De plus Eric ne génère (avec ses hypothèses) qu'un seul prédicteur Z tiré au sort pour chaque t de l'échantillon d'apprentissage ce qui est très peu si on veut tenir compte de l'aléa des latentes "inconnues" de façon cohérente. Le tirage au sort d'un seul prédicteur est trop différent de l'utilisation systématique de statistiques résumantes **observables**.

 En effet dans la deuxième phase prédictive de la BFS, Eric utilise la NQT avec ces soi-disant distributions marginales de Z1 ET Z2. En fait et de façon cohérente, et d'après Krzysztofowicz, c'est la distribution marginale de l'information X et donc les observables conditionnantes des Z (moyennes et écarts types ) qui doivent intervenir si ces latentes sont utilisées en prédictif (voir ci dessus).

## Echangeabilité et Exhaustivité 

 Le point de vue ci dessus est justifié par la théorie de l'échangeabilité car de plus on utilise ainsi les relations entre échangeabilité et exhaustivité (voir Lauritzen 2007 - Sufficiency, Partial Exchangeability, and Exponential Families) et les nouvelles formulations du théorème de représentation de de Finetti qui montrent que dans le conditionnement les Z peuvent être remplaçées par des statistiques exhaustives conditionnelles, dites résumantes, si le modèle d'ensemble le permet ce qui est notre cas). 

 L'avantage considérable est de remplacer les Z latents inobservables par des --statistiques ponctuelles observables t à t--, moyennes et écart-types d'ensemble dont **les distributions marginales sont aussi parfaitement déterminées** (par les paramètres plus g plus S) et donc justiciables d'une NQT sans difficultés. Toutes ces propriétés peuvent être adaptées aux modèles de prévision des précipitations. (j'en ai maintenant la théorie complète avec ces hypothèses pour le modèle des fuites - en cours) 

 Je crois qu'il est nécessaire de suivre alors au plus près la coherence (au sens de Lindley) eu égard aux aspects plus ou moins non-paramétriques des différentes methodes "d'habillage" avec des verbalisations pseuco-statistiques de la littérature et aux difficultés de "lecture" des CRPS continus.

# Séquences de tigy"versets" ("chunks") à la mode JB

## Les données disponibles

Ce sont les données journalières de températures fournies par EDF-DTG aux stations suivantes:

- l' Ain à Vouglans, 

- le Buech à Chambons,

- le Drac au Sautet.

C'est l'Ain à Vouglans qui est notre objet ici. On reprend les data.frames d'Eric: l'"historique journalier" sur la période 1953 à 2015 dans le *data.frame dhisto*, ainsi que celui des "$50$ membres du Centre Européen de Prévision" pour les années 2005 à 2008 (4 ans avec échéance de 1 à 7 jours) puis de 2O11 à 1015 (5 ans pour des prévisions jusqu'à une échéance de 9 jours) à Vouglans dans le *data.frame dtout*.

# Un coup d'oeil sur les données repris D'Eric

```{r}
dhisto %>% glimpse
range(dhisto$Date)
dtout %>% head()
dtout %>% group_by(Year) %>% summarize(MaxEcheance=max(Echeance), counts=n())
```

## Analyse climatologique

Eric a illustré les fortes fluctuations saisonnières des températures journalières au cours de l'année:

```{r}
Year<-dhisto[,5]
dhisto %>% mutate(an= factor(Year)) %>% 
ggplot(aes(x = Calendaire, y= T, color = an)) + geom_line(alpha=0.5)
horsain = ymd("2003-10-15")
```

On voit apparaître un comportement très sûrement aberrant en date du 2003-10-15, horsain dont on enlève l'année 2003 complète du fichier historique dhisto.

```{r}
dhisto %>% filter(Year!= 2003) %>% mutate(an=factor(Year)) %>% ggplot(aes(x = Calendaire, y= T)) + geom_point(aes( color = an),alpha=0.5, shape ='.', show.legend = FALSE)+geom_smooth()+labs(x='Jours Calendaires', y='Températures', title="Climatologie à Vouglans")
```

# Première modification JB

*ERic:OK, avec qqs améliorations pour rendre plus explicites*
On va alors construire une température moyenne de réference lissée pour chaque jour calendaire de l'année. Pour construire ces estimateurs lissés périodiques, on *régresse*, en fonction des 4 premières harmoniques, **les températures interannuelles sur la base calendaire moyenne** après élimination des années bissextiles. Les températures désaisonnalisées sont appelées %T_ecart%. Contrairement à Eric, on ne procède pas à la regression sur les variances mais à un classement par saison- voir plus loin.

 On doit noter que le rejet "bissextile" par la variable calendaire=366 rejette en fait la dernière observation de chaque année bissextile c'est à dire le *31 décembre*. Nous avons conservé ceci pour le calcul des valeurs climatiques ajustées (T_ref_lis)

J'ai repris la première partie du chunk d'Eric + une série de plots d'illustration (avec titres) mais sans ggplot.

```{r}
dhisto %>% filter(Year!= 2003, Calendaire != 366) -> histo_ref
tt<-1:(dim(histo_ref)[1]) # 62*365=22630
modlin<-lm(T~ 1+ sin(2*pi*tt/365)+
          cos(2*pi*tt/365)+
          sin(4*pi*tt/365) +
          cos(4*pi*tt/365)+
          sin(6*pi*tt/365) +
          cos(6*pi*tt/365)+
          sin(8*pi*tt/365)+
          cos(8*pi*tt/365), data=histo_ref
          )
histo_ref %>% mutate(T_ref_lis=modlin$fitted.values,T_ecart=T-T_ref_lis) -> histo_ref
T_ecart<-as.numeric(histo_ref$T_ecart,narm=FALSE)
calend<-as.numeric(histo_ref$Calendaire,narm=FALSE)
statec<-matrix(NA,365,2)
for(j in 1:365){
  statec[j,] <- c(mean(T_ecart[which(calend==j)]),sd(T_ecart[which(calend==j)])) 
 }
MoyEcartClim<-statec[,1]
SdEcartClim<-statec[,2]
HC<-hist(T_ecart,100,right=FALSE,plot=FALSE)
dhc<-HC[[3]]
lhc<-HC[[4]]
N<-length(T_ecart)
MTE<-mean(T_ecart)
SDTE<-sd(T_ecart)
plot(1:N,T_ecart,"p",main="Chronologie des écarts clim. journaliers", pch=".",cex=1.5)
grid(nx=NULL,ny=NULL,lty=6)
plot(1:365,MoyEcartClim,typ="b",main="MoyEcartClim : Moyenne des écarts clim.",pch=19, xlab="jours calendaires")
grid(nx=NULL,ny=NULL,lty=6)
plot(lhc,dhc, "h",main="Histogramme et ajustement normal",
     xlab="Ecart vis à vis de la température climatologique",
     ylab="densité empirique")
grid(nx=NULL,ny=NULL,lty=6)
lines(lhc,dnorm(lhc,MTE,SDTE),"l",col="red") 
plot(1:365,SdEcartClim, "b",main="SdEcartClim : Ecart-type des écarts clim.", pch=19, xlab="jours calendaires")
grid(nx=NULL,ny=NULL,lty=6)
autoc<-acf(T_ecart,lag.max=10,plot=TRUE, sub="Autocorrélation journalière")
lcl<-c(qnorm(0.25,MTE,SDTE),qnorm(0.75,MTE,SDTE))
print(c("Nombre de T_ecarts  Moyenne   Ecart-type"))
print(c(N,MTE,SDTE),digit=5)
```


## Commentaires de JB:

*ERic:OK*
les  5 graphes ci dessus se veulent vérifier la stationnarité et la normalité des variables "T_ecarts" désaisonnalisées. On notera de plus que les autocorrélations sont notables mais très légèrement biaisées puisque, pour les fins d'années bissextiles, les écarts du 01/01 de l'année suivante sont reliés à ceux du 30/12 de l'année bissextile précèdente du fait de la selection opérée pour le calcul sur l'ensemble des données historiques et non les seules moyennes comme le fait Eric. 

La technique BFS laissera la possibilité d'introduire, au niveau prédictif, les températures observés des jours précédents comme prédicteur conjointement aux Z ou leurs résumés. 

 On notera les bons résultats globaux de cette desaisonnalisation simplifiée. Cependant il reste une variation calendaire de l'écart-type SdEcartClim (5éme graphe). Je pense qu'on peut se contenter  d'une possibilité de variation sur deux saisons été (8 mois) et hiver (4 mois)dans une première approximation.
 
## Dans ce premier jet de Previtemps nous n'avons tenu compte que de la saison 2 (été: 8 mois d'avril à novembre) pour illustration.##
 
 Les deux saisons sont cependant introduites comme variables dans "histo_ref".

### Illustration 

On utilisera donc cette variable T_ecart de la saison 2 (été) du fichier  histo_ref constituant la variable désaisonalisée climatique pour estimer les modèles d'ensembles et construire les variables de Brier, discrètisées ici en 3 classes de cette variable T_ecart supposée normale + tests divers (PIT, Cramer Von Mises). C'est bien sûr une discrétisation très sommaire pour première illustration. Les limites climatiques de ces classes d'écarts de température: §(.<=-2.409, -2.409<.<=2.409, .>2.409)§  correspondent aux probabilités normales de classe (0.25,0.50,0.25) de --T_ecart climatique générales--. Elles seront abandonnées au profit des mêmes limites calculées sur les données de l'été ci après.

-----------------------

# Constitution des fichiers intermédiaires avant calcul
*ERic:OK*
 Maintenant on selectionne selon la saison 2 et on constitue le fichier utile intermédiaire "dbs", en joignant les moyennes et écarts types d'ensemble à dtout, tibble de base d'Eric.

 On sort les propriétés statistiques de la saison sélectionnée ainsi,que les limites de classes générales pour le Brier. Ces limites peuvent être changées (notamment pour les calculs CEP).

```{r}
histo_ref %>% 
  mutate(Saison=if_else(Month < 4| Month >11, 1, 2))%>% 
  filter(Saison!=1) ->histoETE
T_ecart<-as.numeric(histoETE$T_ecart,narm=FALSE)
HC<-hist(T_ecart,100,right=FALSE,plot=FALSE)
dhc<-HC[[3]]
lhc<-HC[[4]]
N<-length(T_ecart)
MTE<-mean(T_ecart)
SDTE<-sd(T_ecart)
plot(1:N,T_ecart,"b",main="T_écarts d'été", xlab='244 jours fois 62 années', pch=19, cex=.3)
grid(nx=NULL,ny=NULL,lty=6)
Mois<-histoETE$Month
ms<-c(4:11)
MTm<-rep(NA,8)
SDTm<-rep(NA,8)
for(j in 1:length(ms)){
MTm[j]<-mean(T_ecart[which(Mois==ms[j])])  
SDTm[j]<-sd(T_ecart[which(Mois==ms[j])])
}
plot(4:11,MTm,"l",main="Moyennes mensuelles",lwd=3)
lines(4:11,rep(MTE,8),"l",col="red",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(4:11,SDTm,"l",main="Ecart_types mensuels",lwd=3) 
lines(4:11,rep(SDTE,8),"l",col="red",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(lhc,dhc, "h",main="Histogramme des écarts de temp. clim. d'été")
lines(lhc,dnorm(lhc,MTE,SDTE),"l",col="red")
grid(nx=NULL,ny=NULL,lty=6)
lcl<-c(qnorm(0.25,MTE,SDTE),qnorm(0.75,MTE,SDTE))
print("N et limites de classes choisies")
print(c(N,lcl))
print("moyenne  écart_type globaux")
print(c(MTE,SDTE))
```

 On notera les limites de classes {-2.26, 2.19},légèrement différentes puisqu'elles sont ici relatives à la saison 2 d'apprentissage sélectionnée sur 4 ans. L'hypothèse de normalité des "T_ecart" historiques reste satisfaisante pour la saison. On y notera aussi une variation mensuelle résiduelle des moyennes et ecart_types qui relativise une complète désaisonnalisation. Le mois d'avril pose peut être question.
On travaille ensuite sur le fichier avec les ensembles

```{r}
# ------------
dtout %>% filter(Calendaire != 366) %>%  
mutate(Saison=if_else(Month<4|Month>11,1,2), Xbar=rowMeans(dplyr::select(.,starts_with("Run"))),
SDx=apply(dplyr::select(.,starts_with("Run")),1,sd)) %>% 
filter(Saison!=1) ->dbs
```


 
## ----------------- 

Ensuite on selectionne la période d'apprentissage (2005 - 2008) donnant histoETEapprentissage et dbsApprentissage puis Tcal0: première selection de colonnes utiles du fichier historique.


```{r}
dbs%>% mutate(apprent=if_else(Year<2010,1,2)) %>%
  filter(apprent!= 2) -> dbsApprentissage
histoETE%>%mutate(dansBase=if_else(Year<2005|Year>2008,1,2))%>%
  filter(dansBase!= 1) -> histoETEapprentissage
dim(dbsApprentissage)
dim(histoETEapprentissage)
Tcal0<-histoETEapprentissage[,c(4,7,8,9,10)]
head(Tcal0)
```

## Puis "CHOIX DE L'ECHEANCE" de ECHba parmi les 1:7 possibles. 

Le cas choisi est l'échéance 4
Ensuite combinaison des deux tibbles: histoETE (données historiques) et dtoutba que l'on joint à Tcal0 pour obtenir par selection le tibble Tcala pour cette échéance en période d'apprentissage). 

--Le fichier de travail final d'apprentissage est donc Tcala.--

Pour les 3 modèles d'ensemble la variable modélisée est donc **la variable T_cart**  de la sous période supposée stationnaire choisie

```{r}
ECHba<-4
dbsApprentissage%>%filter(Echeance==ECHba) -> dtoutba 
dtoutba<-bind_cols(dtoutba,Tcal0)
sum(abs(dtoutba$T-dtoutba$Obs)) # Ouf!
dtoutba<-mutate(dtoutba,T_ecart=T-T_ref_lis,Xbar=Xbar-T_ref_lis)
#Tcala<-dtoutba[, c(1,3,55,57:62:64)]
Tcala<-dtoutba %>% dplyr::select(Date,Obs,Month,Saison:T_ecart)
nav<-which(is.na(Tcala[,5]))
Tcala<-Tcala[-nav,]
dEbas<-as.matrix(dtoutba[,c(4:53)])
Eas<-dEbas[-nav,]
head(Tcala)
head(Eas)
```

 En bref nous avons choisi l'échéance 4 pour illustration de l'apprentissage sur 2005-2008.
 


* Au départ on choisit donc l'apprentissage Tcala mais on peut choisir un échantillon annuel Tcalv dont le "chunk potentiel pour plus tard" est donné ci après hors du champ des chunks executables. Cependant, "pour le post-traitement CEP" il n'a pas de différences car, en dehors des moyennes et écarts types il n'y a pas de modèle ou paramètres particuliers à estimer (si le modèle normal est choisi a priori). Dans chaque cas on dispose de pseudo-prédictives pour autant que la loi normale soit respectée.

* --Pour le moment nous ne traitons donc que la période d'apprentissage 2005-2008.
**en sautant le chunk potentiel de choix annuel suivant**. néccessaire ultérieurement pour la validation des prévisions



### Calcul validation annuel. (pour plus tard) 

On commence par le choix de l'année dans dbs et histoETE puis le Choix de l'échéance en validation et construction du fichier utile final Tcalav par selection et combinaison Tcalv.
Ce chunk n'est pas pris en compte pour notre premier HTML sorti.

```
###----------------------

dbs%>% mutate(valid=if_else(Year==2012,1,2)) -> dbsv
dbsv%>%filter(valid!= 2) -> dbsv
histoETE%>%mutate(valid=if_else(Year==2012,1,2))  -> histoETEv
histoETEv%>%filter(apprent!= 2) -> histoETEv
dim(dbsv)
dim(histoETEv)
Tcal0v<-histoETEapprentissage[,c(4,7,8,9,10)]
head(Tcal0v)
# ----------------------------
ECHbv<-1
dbsv%>%filter(Echeance==ECHbv) -> dbsv 
dbsv<-bind_cols(dbsv,Tcal0v)
dbsv<-mutate(dbsv,T_ecart=T-T_ref_lis,Xbar=Xbar-T_ref_lis)
Tcalv<-dbsv[, c(1,3,55,57:62:64)]
head(Tcalv)

###----------------------
```

# Analyse de la structure des données d'apprentissage

## Structure des données par analyse en composantes principales

Cette analyse est importante car elle permet un jugement sur l'hypothèse échangeable.

```{r}
nn<-dim(Eas)
S<-nn[2]
MA<-apply(Eas,2,"mean")
SdA<-apply(Eas,2,"sd")
ACP<-princomp(Eas,cor=TRUE,scores=TRUE)
sdF<-ACP[[1]]
cdF<-ACP[[2]]
vdF<-ACP[[6]]
varcum<-cumsum(sdF*sdF)/sum(sdF*sdF)
Inert<-sdF*sdF/sum(sdF*sdF)
coef<-c(1 ,rep(100,9))
print(Inert[1:10])
plot(1:10,Inert[1:10], "l",col="red",lwd=5, main="inerties x 100 des rangs 2:10 en noir")
lines(1:10,coef*Inert[1:10], "l",col="black",lwd=5,lty=2)
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,cdF[,1],"b",pch=19,lwd=1,main="poids des membres dans 1er facteur")
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,MA,"b",pch=19,lwd=1,main="Moyennes des membres d'ensemble")
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,SdA,"b",pch=19,lwd=1,main="Ecart-types des membres d'ensemble")
grid(nx=NULL,ny=NULL,lty=6)
```

La première figure représente l'inertie des 10 premiers facteurs rangés par ordre de grandeur.La première composante pèse 96,3% de l'inertie totale. Pour faire apparaître les suivantes nous les avons multipliés par 100, en noir sur la figure. On voit le très grand poids de cette première composante.

Les figures suivantes donnent, pour la seconde, le poids de chacun des 50 membres dans l'expression de cette composante très dominante. Il est clair que ces poids sont très sensiblement égaux ce qui signifie que cette composante est très proche de la moyenne d'ensemble Xbar. Les dernières figures montrent que les moyennes marginales sur 2005-2009 de chaque membre sont assez semblables de même que les écart-types ce qui va dans le sens de l'hypothèse d'échangeabilité.

--Compte tenu de ces résultats et surtout de l'importance d'une seule composante, nous avons décider d'incorporer dans notre comparaison , le modèle échangeable simple à 1 pivot.--


# Données climatiques Tds (vecteur) et variables catégorisées clim. BT  ET Pcep (matrices 3 colonnes)

Comme référence climatique on a pris les seuils de classe (-2.26, 2.19) qui sont les valeurs de T_ecart normales d'été (quantiles 0.25 et 0.75) pour la série climatique complète depuis 1953.

 Les distributions de ces valeurs journalières seront aussi vérifiées.


```{r}
# On a pu choisir une année particulière avec Tcalv ou l'échantillon de calage Tcala
#Tcalv%>%filter(!is.na(Xbar)) -> Tcalv
Tcala%>%filter(!is.na(Xbar)) -> Tcala
# Tds est le vecteur d'Ecarts de températures d'apprentissage
Tds<-as.numeric(Tcala$T_ecart,narm=FALSE)
MY<-mean(Tds)
SdY<-sd(Tds)
lca<-lcl
n<-length(Tds)
BT<-matrix(NA,length(Tds),3)
br<-c(qnorm(0.00001,MY,SdY),lca[1],lca[2],qnorm(0.99999,MY,SdY))
for(j in 1:n){
HB<- hist(Tds[j],br,plot=FALSE)
BT[j,]<-HB[[2]]
}
PBT<-apply(BT,2,"sum")/n
HT<-hist(Tds,50,right=FALSE,plot=FALSE)
dht<-HT[[3]]
lht<-HT[[4]]
plot(lht,dht, "h",main="histogramme de T_écart")
lines(lht,dnorm(lht,MY,SdY),"l",col="red")
print("Nombre,  Moyenne et Ecart-type clim. de T_écart")
print(c(n,MY,SdY),digits=4)
print("Fréquences de classes en apprentissage")
print(c(PBT))
print("valeurs CEP")
MTcep<-as.numeric(Tcala$Xbar,na.rm=FALSE)
SDTcep<-as.numeric(Tcala$SDx,na.rm=FALSE)
# La matrice Pcep donne les prédicteurs cep par classe
Pcep<-matrix(NA,n,3)
Pcep[,1]<-pnorm(rep(lca[1],n),MTcep,SDTcep)
Pcep[,2]<-pnorm(rep(lca[2],n),MTcep,SDTcep)-pnorm(lca[1],MTcep,SDTcep)
Pcep[,3]<-1-pnorm(rep(lca[2],n),MTcep,SDTcep)
print("Moyennes des probabilités CEP")
print(apply(Pcep,2,"mean"))
```

**Ici rappelons que l'échéance 4 a été choisie**

Une indication de la valeur du modèle normal de température climatique est donnée en comparant les fréquences du vecteur BTP (sur 4 ans d'apprentissage) aux probabilités de référence $(0.25 , 0.50 , 0.25)$ ce qui montre un décalage pour les températures supérieures à la moyenne. Il y a donc une certaine différence entre la climatologie historique de référence et la période d'apprentissage De plus on verra que les moyennes de probabilités de classes CEP montrent un net resserement de la dispersion précisé sur le chunk ci après.



##On passe maintenant à la validation du modèle CEP puis à la représentation catégorisée des données en vue du calcul des Briers.

 A partir du fichier de base en apprentissage Tcala on calcule les valeurs discrètisées des écarts de température climatique et prévisions CEP journaliers sur **l'apprentissage**.  Rappelons que les prévisions probabilistes journalières CEP sont supposées normales de moyennes MTcep et écarts types SDTcep (d'après Eric).
 

```{r}
ng<-n
Tred<-(Tds-MTcep)/SDTcep
HT<-hist(Tred,50,right=FALSE,plot=FALSE)
dhc<-HC[[3]]
lhc<-HC[[4]]
nr<-length(Tred)
MTr<-mean(Tred)
SDTr<-sd(Tred)
plot(lhc,dhc, "h",main="histogramme de T réduit")
lines(lhc,dnorm(lhc,MTr,SDTr),"l",col="red",lwd=6)
pTred<-pnorm(Tred,0,1)
plot(1:nr,sort(pTred),"l",col="red",main="Distribution cumulée de T réduit")
lines(1:nr,(1:nr)/(nr+1))
grid(nx=NULL,ny=NULL,lty=6)
hist(pTred,seq(0,1,0.10),main="Histogramme PIT",col="blue")
lines(0:10,rep(100,11),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
ttnorm<-cvm.test(Tred,"pnorm",mean=MTr,sd=SDTr)
ttpit<-cvm.test(pTred,"punif")
print(ttnorm)
print(ttpit)
# ------------------
Tredg<-Tred[1:ng]
lg<-c(0.25,0.50,0.75)
ainf<-qnorm(rep(lg[1],ng),MTr,SDTr) 
asup<-qnorm(rep(lg[3],ng),MTr,SDTr)
va1<-length(which(Tredg<=ainf))/ng
va2<-length(which(Tredg<=asup&Tredg>ainf))/ng
va3<-length(which(Tredg>asup))/ng
print("marges T et cep")
print(c(PBT[1],va1))
print(c(PBT[2],va2))
print(c(PBT[3],va3))
```



 
 
 
 Le chunk qui précède concerne d'une part les graphes de distribution de Tred (écarts de T. en apprentissage --centrés, réduits-- jour par jour avec les paramètres CEP de l'échéance 4) comparés aux distributions normales. La forte réduction de dispersion des écarts ainsi réduits de la --température naturelle-- doit être notée (première figure). La 2ème figure représente la même distribution après anamorphose normale (la NQT) dans le graphe classique où la référence normale est représentée par la droite noire.
 En troisième graphe on donne le diagramme PIT habituel des prévisionnistes pour cette période d'appentissage sur 10 classes (suite à la lecture des documents Luc Perreault). Ce diagramme ne donne pas autre chose que la même distribution précédente supposée prédictive (pour les ensembles CEP) et représentée en histogramme après anamorphose uniforme (par la f.r). 
 
Sur ces deux distributions nous avons calculé le test d'ajustement **omega2 de Cramer Von Mises**.
1- sur Tred, on a:
ttnorm --> omega2 = 0.46438, p-value = 0.04909
2- sur la prédictive uniforme (PIT)
ttpit-> omega2 = 7.3647, p-value = 2.935e-12
Concluons que la loi normale est "limite" pour l'apprentissage. Pour la validité des prévisions CEP "sur l'appentissage" le test ttpit est franchement très mauvais. De fait le résultat de ce test combine les deux effets: ajustement normal médiocre pour l'apprentissage et très mauvaise qualité prédictive de la méthode CEP.

NOTA BENE: C'est affreux j'utilise ici les pvalues d'un test fréquentiste classique mais j'assume que le résultat parle au bayesien ici.

## répartition par classes

On donne aussi le tableau des probabilités marginales "cible" et "prévision" par classe standardisée avec des ecarts importants entre les distributions.

*Éric: OK*
--------------

# ANALYSE DECISIONNELLE:  Briers discrètisés et généralisés selon Degroot et Fienberg(1983)

* On notera donc $y_{j}$ (Bernoulli généralisé type 0,1,0) et $a_{i}$, avec indices explicites, l'évènements réalisé, valeur cible observée d'une part et la valeur annoncée selon la prévision probabiliste d'autre part chaque jour. En quelque sorte $a_{i}$ est la valeur de la prévision probabiliste discrètisée dont on calcule le score dépendant de $y_{j}$. De la décision $a_{i}$ et de $y_{j}$ réalisés résultera donc un coût quadratique (de Brier généralisé dissymétrique):

$$W(a,y)=\sum W_{i,j}(a_{i}-y_{j})^{2}$$

que l'on calcule connaissant:

1. $va=[a]$ la distribution de probabilité marginale de prévoir $a_{i}$ ce jour là. Dans le contexte bayesien le vecteur va peut être interprété comme le resumé de l'information choisi ce jour pour prévoir l'état de la nature $y_{j}$.
2. une famille de $k$ distributions conditionnelles des probabilités d'observer jours où $a_{i}$ a été émis comme prévision. Pour l'apprentissage cette famille est donnée par la matrice:

$\rho_{ij}=\frac{[y_{j}][a_{i}|y_{j}]}{\sum_{j=1}^{k}[y_{j}][a_{i}|y_{j}]}=[y=y_j|a=a_i]$

Pour exemple et par anticipation selon le chunk suivant, on a:

va
0.22 0.57 0.21

ro
y/a     [,1]  [,2]  [,3]
[1,]    0.05 0.09 0.08
[2,]    0.13 0.24 0.20
[3,]    0.05 0.09 0.07

*Éric: NB, Tu donnes la conjointe, pas la conditionnelle.*

* Maintenant on calcule, pour chaque jour de la période d'apprentissage et pour la totalité de la période) les scores de Briers moyens: total BS, la part BS1 (imputée au calibrage imparfait) et BS2 la part dûe à l'imprécision (écart) de la prévision


```{r}
# La matrice Pcep donne les probabilités des prédicteurs cep par classe
MTcep<-as.numeric(Tcala$Xbar,na.rm=FALSE)
SDTcep<-as.numeric(Tcala$SDx,na.rm=FALSE)
Pcep<-matrix(NA,n,3)
Pcep[,1]<-pnorm(rep(lca[1],n),MTcep,SDTcep)
Pcep[,2]<-pnorm(rep(lca[2],n),MTcep,SDTcep)-pnorm(lca[1],MTcep,SDTcep)
Pcep[,3]<-1-pnorm(rep(lca[2],n),MTcep,SDTcep)
BS<-rep(NA,n)
BS1<-rep(NA,n)
BS2<-rep(NA,n)
ybar<-matrix(NA,n,3)
va<-matrix(c(va1,va2,va3),3,3)
py<-matrix(PBT,3,3,byrow=TRUE)
# ro est la matrice des probabilités conjointes cible y, prévision a avec PBT comme prior
ro<-va*py
ybar<-matrix(NA,n,3)
YM<-rep(NA,n)
W<-matrix(c(1,1,1),3,3)
for (j in 1:n){
 pT<-Pcep[j,]
 bTy<-BT[j,]
 a<-matrix(c(pT),3,3)
 y<-matrix(bTy,3,3,byrow=TRUE)
 ybarj<-apply(y*ro,1,"sum")/apply(ro,1,"sum")
 ybar[j,]<-ybarj
 ybarm<-matrix(ybarj,3,3)
 bs0<-apply(ro*W*(a-y)^2,1,"sum")
 bs<-sum(va*bs0)
 bs10<-apply(ro*W*(a-ybarm)^2,1,"sum")
 bs1<-sum(va*bs10)
 bs20<-apply(ro*W*(ybarm-y)^2,1,"sum")
 bs2<-sum(va*bs20)
 BS[j]<-bs  
 BS1[j]<-bs1  
 BS2[j]<-bs2
 YM[j]<-mean(ybarj)
}
BSt<-mean(BS,na.rm=TRUE)
BS1t<-mean(BS1,na.rm=TRUE)
BS2t<-mean(BS2,na.rm= TRUE)
Mybar<-apply(ybar,2,"mean")
SDybar<-apply(ybar,2,"sd")
plot(1:n,BS,"b",pch=19,cex=0.5)
hist(BS,50,main="histogramme des scores journaliers")
print("liste des probabilités de va, ro")
print(list(c(va1,va2,va3),ro))
print("Moyenne de ybar")
print(mean(YM))
print("*Briers moyen global - dû au calibrage - dû à la précision et pourcentages")
print(c(BSt,BS1t,BS2t))
print(c("Pourcentages"))
print(c(BS1t/BSt,BS2t/BSt))
```

Pour la période d'apprentissage 2005-2008, les resultats ci dessus sont les scores de Brier moyens journaliers: total, BS1: la part interprétée comme imputable à l'absence de calibrage et BS2: la part dûe au manque de précision. Je donnerai les formules dans la note annexe . Je ne peux les sortir en LATEX ici (sorry)
*Éric: OK, mais je pense qu'il faut faire une fonction*
    BS1=∑_{i=1}^{k}∑_{j=1}^{k}υ(a_{i})ρ_{ij}([a_{i}]-y_{a_{i}}^{(ρ)})²
    BS2=∑_{i=1}^{k}∑_{j=1}^{k}υ(a_{i})ρ_{ij}(y_{a_{i}}^{(ρ)}-y_{j})²
    
    
   
comme dans le cas Binaire le score de Brier peut se décomposer en deux : BS2 la part dûe à la précision propre au modèle de traitement de l'ensemble de prévision, BS1 la part dûe au manque de calibrage de l'ensemble   

*Éric: les voilà, tes formules en latex!*
$$BS1=\sum_{i,j} v(a_{i}) W_{ij} (a_{i}-\rho_{j|i})^{2}$$
$$BS2=\sum_{i,j} v(a_{i}) W_{ij}\times \rho_{j|i}\times(1-\rho_{j|i})$$

# ------------------

# Calcul de Brier assymétrique avec regret paramétré Wij dans les classes centrale et extreme (1,0,0).
#Excusez la longueur du chunk -j'ai voulu faire plusieurs fonctions de coût en même temps et sortir 6 plots : C'EST MA FAUTE, MA TRES GRANDE FAUTE: je ne sais pas vraiment utiliser des ggplots compliqués.

```{r}
W<-matrix(c(1,1,1),3,3)
W1<-matrix(c(1,5,1),3,3,byrow=TRUE)
W2<-matrix(c(5,1,1),3,3,byrow=TRUE)
BSW<-matrix(NA,n,3)
BSW1<-matrix(NA,n,3)
BSW2<-matrix(NA,n,3)
aopt<-rep(NA,n)
aopt1<-rep(NA,n)
aopt2<-rep(NA,n)
yobs<-rep(NA,n)
erreur<-rep(NA,n)
va<-matrix(c(va1,va2,va3),3,3)
py<-matrix(PBT,3,3,byrow=TRUE)
# ro est la matrice des probabilités conjointes cible y, prévision va avec PBT comme prior
ro<-va*py
BS<-rep(NA,n)
BS1<-rep(NA,n)
BS2<-rep(NA,n)
for (j in 1:n){
 pT<-Pcep[j,]
 bTy<-BT[j,]
 a<-matrix(c(pT),3,3)
 y<-matrix(bTy,3,3,byrow=TRUE)
 ybarj<-apply(y*W*ro,1,"sum")/apply(W*ro,1,"sum")
 ybarm<-matrix(ybarj,3,3)
 bsW0<-apply(ro*W*(a-ybarm)^2,1,"sum")
 bsW<-sum(va*bsW0)
 BSW[j,]<-bsW
 ybarj1<-apply(y*W1*ro,1,"sum")/apply(W1*ro,1,"sum")
 ybarm1<-matrix(ybarj1,3,3)
 bsW10<-apply(ro*W1*(a-ybarm1)^2,1,"sum")
 bsW1<-sum(va*bsW10)
 BSW1[j,]<-bsW1
 ybarj2<-apply(y*W2*ro,1,"sum")/apply(W2*ro,1,"sum")
 ybarm2<-matrix(ybarj2,3,3)
 bsW20<-apply(ro*W2*(a-ybarm2)^2,1,"sum")
 bsW2<-sum(va*bsW20)
 BSW2[j,]<-bsW2
aopt[j]<-as.numeric(which.min(bsW0))
yobs[j]<-as.numeric(which.max(bTy))
aopt1[j]<-as.numeric(which.min(bsW10))
aopt2[j]<-as.numeric(which.min(bsW20))
}
BW<-mean(BSW,na.rm=TRUE)
BW1<-mean(BSW1,na.rm=TRUE)
BW2<-mean(BSW2,na.rm=TRUE)
B<-mean((aopt-yobs)^2,na.rm=TRUE)
B1<-mean((aopt1-yobs)^2,na.rm=TRUE)
B2<-mean((aopt2-yobs)^2,na.rm=TRUE)
NC<-c(1:50)

plot(NC,aopt[NC]-yobs[NC],"l",col="black",main="Erreur_crps: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
plot(NC,aopt1[NC]-yobs[NC],"l",col="black",main="Erreur_coût1: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
plot(NC,aopt2[NC]-yobs[NC],"l",col="black",main="Erreur_coût1: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
NEc<-rep(NA,5)
NEc1<-rep(NA,5)
NEc2<-rep(NA,5)
Ec<-as.vector(c(-2,-1,0,1,2))
for (j in 1:5){
  NEc[j]<-length(which(aopt-yobs==Ec[j]))
  NEc1[j]<-length(which(aopt1-yobs==Ec[j]))
  NEc2[j]<-length(which(aopt2-yobs==Ec[j]))
}
plot(Ec,NEc/n,"l",sub="Fréquences des écarts de prévision",col="black",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(Ec,NEc1/n,"l",sub="Fréquences_coût1 des écarts de prévision",col="red",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(Ec,NEc2/n,"l",sub="Fréquences_coût2 des écarts de prévision",col="green",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
MoyEcartClimart<-matrix(data = c(NEc/n,NEc1/n,NEc2/n),3,5,byrow=TRUE)
print("Briers: W111 W151  W511")
print(c(BW,BW1,BW2))
print("Fréquences moyennes des écarts de prévision")
print(MoyEcartClimart,digits=3)
print("Moyennes quadratiques de ces écarts")
print(c(B,B1,B2),digits=3)
```

--Commentaire-- Même avec ces fonctions de coût sommaires on voit leur rôle important sur le choix des --prévisions terminales (différent des prévisions probabilistes)-- et donc ceci montre le caractère éventuellement inadéquat (pour le point de vue opérationnel de l'utilisateur des prévisions) des critères symétriques comme le CRPS ou le ROC.

On rappelle que la courbe ROC (Receiver Operating Caracteristic) des prévisions binaires (E,nonE) fournit les rapports de probabilité de détecter E à la probabilité de détecter nonE en fonction de divers évènements nonE. Comparer les deux évènements par leurs probabilité revient à supposer les regrets égaux. Cette remarque peu s'appliquer aussi au diagramme PIT.

-------------
```{r}
BRIERCategoriel = function(pred=matrix(c(0.5,0.2,0.3,
                                        0.4,0.4,0.2,
                                        0.5,0.2,0.3,
                                        0.1,0.4,0.5),
                                       byrow=T,nr=4),# matrice de previsions
               obs=matrix(c(1,0,0,
                            0,1,0,
                            0,0,1,
                            0,1,0),byrow=T,nr=4),# matrice d'observations
               W =matrix(c(1),nr=3,nc=3)# matrice de ponderation
               ) {
  n=dim(pred)[1]
  p=dim(pred)[2]
  if (((dim(obs)[1]!=n)|(dim(obs)[1]!=n))) stop ("Problème de dimensions incompatibles")
  if (((dim(W)[1]!=p)|(dim(W)[1]!=p))) stop ("Problème de dimensions de W incompatibles")
  if (sum(obs)!=n) stop ("l'observation doit contenir des 1 seulement")
  pred=pred/apply(pred,1,sum)
  bs=0*(1:n)
  for (t in 1:n)  bs[t]=sum((outer(pred[t,],obs[t,],"-")^2)*W)
}
BS=mean(bs)

conjointe= t(obs)%*%pred/n
colnames(conjointe)=paste("pred =",1:p)
rownames(conjointe)=paste("obs =",1:p)
margepred=apply(conjointe,2,sum)  # notée v chez DEgroot et Feinberg
condObsSachantPred= conjointe/margepred  # notée rho chez DEgroot et Feinberg


```


# Modèles échangeables d'ensemble à 1 et 2 pivôts

On fait l'apprentissage des modèles sur la même période (2005-2008). 

JB: j'ai repris les chunks du JAGS d'Eric pour l'inference Gibbs du modèle échangeable_BFS 2 simplement en reconstruisant le kibble apprentissage  à partir de Tcala. plus loin après le modèle E1 simple.

## Modèle à 1 pivot

Ce modèle peut être considéré comme un constituant (pour chaque ensemble {e}) du modèle multiple utilisé maintenant par Luc. 

Pour ce modèle E1 dont l'inference est particulièrement simple, l'estimation des paramètres marginaux par max de vraisemblane normal est possible.
En effet ce modèle s'écrit:

$X_{t,s}=\mu+\lambda Z_{t}+\epsilon_{ts}$ \ \ avec $\epsilon_{ts}%
=N(0,1/\sqrt{h})$ 

la conditionnelle complète de la latente est:

$Z=N(\frac{S\lambda h(Xbar-\mu)}{1+S\lambda^{2}h^{2}},precision=1+S\lambda
^{2}h^{2})$

Il y a deux statistiques résumantes Xbar et V2 (variance) par ensemble qui permettent les estimations marginales des paramètres préquentiels $\mu,\lambda, et h\$ (Commme Eric on suppose ceux ci connus sans erreurs). Mas il n'existe qu'un seul pivôt résumant Z à savoir Xbar.
Voici les estimations ponctuelles (max. de vraisemblance) des paramètres:

\bigskip$h=\frac{K-1}{K.mean(s^{2})}$

\bigskip$\mu=mean(Xbar)$

et si $\s^{2}=var(Xbar)$

\bigskip$\lambda^{2}=var(Xbar)-\frac{h}{S}$

Calculons maintenant \$u\$ la variable centr\'{e}e r\'{e}duite: 


$u=\frac{(Xbar-\mu)}{s}$

Notons que s'appliquant à des variables normales, les NQT redonnent les mêmes variables normales. Notons aussi que --la variance de Xbar est celle résultant du modélé échangeable mrginal-- Pour les cibles normales, cette propriété s'applique aussi aux $y$

On recrée le tibble apprentissage

```{r}
Tcala %>% filter( !is.na(Calendaire1)) %>% 
 mutate(theta=T_ecart,xbar=Xbar, v2=SDx^2) %>%   filter(!is.na(theta),
          !is.na(xbar),!is.na(v2)) -> learning_sample
learning_sample %>%  dplyr::select(theta,xbar,v2) -> apprentissage
```

## Modèle Gamma-Normal à 1 pivot (échangeable_BFS)

On appliquera ici les formules ci dessus directement sans passer par Jags. Il suffit de calculer de calculer (sur l'apprentissage ici) mean(var),mean(Xbar) et var(Xbar).
Il est possible (si on adopte l'apprentissage de y comme climatologie) d'utiliser directement pour cible (NQt) la variable $v$ telle que $v=\frac{(y-mean(y))}{sd(y)}$
On pourra aussi ajouter comme prédicteur, la valeur initiale transformée $v0$ de la cible, estimée directement ici commme $y(t-Echba) avec Echba = delai de prévision choisi
```{r}
y<-apprentissage[,1]
nap<-length(y)
Xbar<-apprentissage[,2]
V2<-apprentissage[,3]
h<-(S-1)/(S*mean(V2))
mu<-mean(Xbar)
lambda2<-var(Xbar)-h/S
U<-(Xbar-mu)/sd(Xbar)
V<-(y-mean(y))/sd(y)
corr<-cor(U,V)
print("correlation pivot-cible")
print(corr)
HV <-hist(V,50,plot=FALSE)
dv<-HV[[3]]
av<-HV[[4]]
plot(av,dv,"h",main="histogramme de la cible")
lines(av,dnorm(av,0,1),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
HU<-hist(U,50,plot=FALSE)
du<-HU[[3]]
au<-HU[[4]]
plot(au,du,"h",main="histogramme du pivot")
lines(au,dnorm(au,0,1),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
A<-mean(V)-corr*sd(V)*mean(U)/sd(U)
B<-corr*sd(V)/sd(U)
C<-sd(V)*sqrt(1-corr^2)
mvp<-A+B*U
sdvp<-rep(C,nap)
Gvp<-pnorm(V,mvp,sdvp)
plot(U,V,"p",main="regression cible-predicteur E1")
lines(U,U,"l",col="red")
grid(nx=NULL,ny=NULL,lty=6)
hist(Gvp,seq(0,1,0.10),main="Histogramme PIT",col="blue")
lines(0:10,rep(100,11),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
print(" Paramètres de la regression cible-predicteur E1")
print(c(A,B,C),digits=4)
```

0n notera la très bonne correlation prédictive $0.9086$ et la bonne distribution uniforme du diagramme de PIT pour 10 classes. Le modèle simple est donc un bon compétiteur pour les comparaisons de modèles.

Sortons les paramètres de la  régression predictive en termes des variables U,V centrées réduites Vpred= A+BU+C*N(0,1):
A=0  B=0.909   C=0.419

**Remarque importante**: Nous avons essayé d'utiliser la température initiale du jour de prévision comme second prédicteur, --cela n'a pas donné d'amélioration en termes de précision--
Ce non-résultat corrobore de fait l'interprètation d'Eric comme quoi --l'ensemble Xts un résumé exhaustif de toute l'information nécessaire à la prévision,-- Y COMPRIS DONC les informations sur les conditions initiales.

# ------------

# ESSAI DE VALIDATION DU MODELE E1

Par histogramme de la prédictive normale,graphe NQT et diagramme PIT corespondant

Ensuite calcul des probabilités à priori de la cible PBT puiS celui des probabilités marginales de prévision selon E1 pour le classement en 3 catégories.
```{r}
Vp<-(V-mvp)/sdvp
nr<-length(Vp)
HT<-hist(Vp,50,right=FALSE,plot=FALSE)
dhc<-HT[[3]]
lhc<-HT[[4]]
MTr<-mean(Vp)
SDTr<-sd(Vp)
plot(lhc,dhc, "h",main="histogramme prédictif selon E1 de la cible")
lines(lhc,dnorm(lhc,0,1),"l",col="red",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
pVp<-pnorm(Vp,0,1)
ttnorm1<-cvm.test(Vp,"pnorm",mean=MTr,sd=SDTr)
ttpit1<-cvm.test(pVp,"punif")
print(ttnorm1)
print(ttpit1)
# ------------------
Vredg<-Vp[1:ng]
lg<-c(0.25,0.50,0.75)
ainf<-qnorm(rep(lg[1],ng),0,1) 
asup<-qnorm(rep(lg[3],ng),0,1)
va1<-length(which(Vredg<=ainf))/ng
va2<-length(which(Vredg<=asup&Vredg>ainf))/ng
va3<-length(which(Vredg>asup))/ng
print("marges T (ou V) et E1")
print(c(PBT[1],va1))
print(c(PBT[2],va2))
print(c(PBT[3],va3))
```

Comme pour la prévision CEP nous avons calculé, sur la distribution prédictive comme sur l'echantillon PIT, pratquement identiques avec E1 nous avons calculé le test d'ajustement **omega2 de Cramer Von Mises**.
1- sur Vp, cible centrée réduite, on a:
ttnorm1 --> omega2 = 0.23988, p-value = 0.2019
La p-value donne un ajustement très acceptable (à comparer aux ajustements très médiocres avec le CEP) 
Pour PIT, comme ici le cramer von misés s'applique sur l'anamorphose normale alors que, pour PIT, il s'applique à l'anamorphose uniforme de la normale sur les mêmes données, il donne les mêmes résultats. On voit d'ailleurs sur le diagramme PIT, le bon ajustement uniforme.



#On passe maintenant à la représentation catégorisée des données en vue du calcul des Briers.

```{r}
#valeurs catégorisées journalières pour E1 Echangeable 1 pivot
n<-length(V)
lca<-c(qnorm(0.25,0,1),qnorm(0.75,0,1))
# La matrice PE1 donne les proba prédictives E1 par classe
PE1<-matrix(NA,n,3)
PE1[,1]<-pnorm(rep(lca[1],n),mvp,sdvp)
PE1[,2]<-pnorm(rep(lca[2],n),mvp,sdvp)-PE1[,1]
PE1[,3]<-1-pnorm(rep(lca[2],n),mvp,sdvp)
print("Limites de classe    | Moyennes des probabilités modèle E1")
print(c(lca,apply(PE1,2,"mean")))
```

Comme les variables U et V sont supposées normales centrée réduites, leurs limites de classes sont celles de la loi normale standard ici. Rappelons en effet que les prévisions probabilistes du modèle E1 sont normales de moyennes mean(Xbar) et écarts types sd(Xbar).
 
##: Distributions marginales cible et prévisions pour E1

```{r}
Vg<-Vredg
ng<-length(Vredg)
lg<-c(0.25,0.50,0.75)
ainf<-qnorm(rep(lg[1],ng),0,1) 
am<-qnorm(rep(lg[2],ng),0,1)
asup<-qnorm(rep(lg[3],ng),0,1)
va1<-length(which(Vg<=ainf))/ng
va2<-length(which(Vg<=asup & Vg>ainf))/ng
va3<-length(which(Vg>asup))/ng
print("Marges Tapprent. et E1")
print(c(PBT[1],va1))
print(c(PBT[2],va2))
print(c(PBT[3],va3))
```

Le dernier résultat donne le tableau des probabilités marginales "cible" et "prévision" par classe standardisée avec des ecarts due au médiocre ajustement normal des données d'apprentissage 2005-2008.

# Calculs des Briers et decomposition calibrage-précision

```{r}
n<-length(V)
BS<-rep(NA,n)
BS1<-rep(NA,n)
BS2<-rep(NA,n)
ybar<-matrix(NA,n,3)
va<-matrix(c(va1,va2,va3),3,3)
pv<-matrix(PBT,3,3,byrow=TRUE)
# ro est la matrice des probabilités conjointes cible y, prévision a avec PV comme prior
ro<-va*pv
ybar<-matrix(NA,n,3)
YM<-rep(NA,n)
W<-matrix(c(1,1,1),3,3)
for (j in 1:n){
 pT<-PE1[j,]
 bTy<-BT[j,]
 a<-matrix(c(pT),3,3)
 y<-matrix(bTy,3,3,byrow=TRUE)
 ybarj<-apply(y*ro,1,"sum")/apply(ro,1,"sum")
 ybar[j,]<-ybarj
 ybarm<-matrix(ybarj,3,3)
 bs0<-apply(ro*W*(a-y)^2,1,"sum")
 bs<-sum(va*bs0)
 bs10<-apply(ro*W*(a-ybarm)^2,1,"sum")
 bs1<-sum(va*bs10)
 bs20<-apply(ro*W*(ybarm-y)^2,1,"sum")
 bs2<-sum(va*bs20)
 BS[j]<-bs  
 BS1[j]<-bs1  
 BS2[j]<-bs2
 YM[j]<-mean(ybarj)
}
BSt<-mean(BS,na.rm=TRUE)
BS1t<-mean(BS1,na.rm=TRUE)
BS2t<-mean(BS2,na.rm= TRUE)
Mybar<-apply(ybar,2,"mean")
SDybar<-apply(ybar,2,"sd")
hist(BS,50,main="histogramme des scores journaliers")
print("liste des probabilités de va, ro")
print(list(c(va1,va2,va3),ro))
print("Moyenne de ybar")
print(mean(YM))
print("*Briers moyen global - dû au calibrage - dû à la précision et pourcentages")
print(c(BSt,BS1t,BS2t))
print(c("Pourcentages"))
print(c(BS1t/BSt,BS2t/BSt))
```

Rappelons les résultats CEP des mêmes scores de Brier
[1] 0.4530588 0.1751532 0.2779056
Certes les chiffres de E1 sont plus petits mais avec des écarts relativement faibles.

1- Rappelons bien sûr que la recherche d'un optimum est de minimiser les Briers qui sont des "regrets".
2- On ne dispose pas de moyens statistiques ici de juger la signification des écarts





# ------------------

# Calcul de Brier assymétrique avec regret paramétré W dans les classes centrale et extreme


```{r}
W<-matrix(c(1,1,1),3,3)
W1<-matrix(c(1,5,1),3,3,byrow=TRUE)
W2<-matrix(c(5,1,1),3,3,byrow=TRUE)
BSW<-matrix(NA,n,3)
BSW1<-matrix(NA,n,3)
BSW2<-matrix(NA,n,3)
aopt<-rep(NA,n)
aopt1<-rep(NA,n)
aopt2<-rep(NA,n)
yobs<-rep(NA,n)
erreur<-rep(NA,n)
va<-matrix(c(va1,va2,va3),3,3)
py<-matrix(PBT,3,3,byrow=TRUE)
# ro est la matrice des probabilités conjointes cible y, prévision va avec PBT comme prior
ro<-va*py
BS<-rep(NA,n)
BS1<-rep(NA,n)
BS2<-rep(NA,n)
for (j in 1:n){
 pT<-PE1[j,]
 bTy<-BT[j,]
 a<-matrix(c(pT),3,3)
 y<-matrix(bTy,3,3,byrow=TRUE)
 ybarj<-apply(y*W*ro,1,"sum")/apply(W*ro,1,"sum")
 ybarm<-matrix(ybarj,3,3)
 bsW0<-apply(ro*W*(a-ybarm)^2,1,"sum")
 bsW<-sum(va*bsW0)
 BSW[j,]<-bsW
 ybarj1<-apply(y*W1*ro,1,"sum")/apply(W1*ro,1,"sum")
 ybarm1<-matrix(ybarj1,3,3)
 bsW10<-apply(ro*W1*(a-ybarm1)^2,1,"sum")
 bsW1<-sum(va*bsW10)
 BSW1[j,]<-bsW1
 ybarj2<-apply(y*W2*ro,1,"sum")/apply(W2*ro,1,"sum")
 ybarm2<-matrix(ybarj2,3,3)
 bsW20<-apply(ro*W2*(a-ybarm2)^2,1,"sum")
 bsW2<-sum(va*bsW20)
 BSW2[j,]<-bsW2
aopt[j]<-as.numeric(which.min(bsW0))
yobs[j]<-as.numeric(which.max(bTy))
aopt1[j]<-as.numeric(which.min(bsW10))
aopt2[j]<-as.numeric(which.min(bsW20))
}
BW<-mean(BSW,na.rm=TRUE)
BW1<-mean(BSW1,na.rm=TRUE)
BW2<-mean(BSW2,na.rm=TRUE)
B<-mean((aopt-yobs)^2,na.rm=TRUE)
B1<-mean((aopt1-yobs)^2,na.rm=TRUE)
B2<-mean((aopt2-yobs)^2,na.rm=TRUE)
NC<-c(1:50)
plot(NC,aopt[NC]-yobs[NC],"l",col="black",main="Erreur_crps: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
plot(NC,aopt1[NC]-yobs[NC],"l",col="black",main="Erreur_coût1: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
plot(NC,aopt2[NC]-yobs[NC],"l",col="black",main="Erreur_coût1: previ. - cible")
grid(nx=NULL,ny=NULL,lty=6)
NEc<-rep(NA,5)
NEc1<-rep(NA,5)
NEc2<-rep(NA,5)
Ec<-as.vector(c(-2,-1,0,1,2))
for (j in 1:5){
  NEc[j]<-length(which(aopt-yobs==Ec[j]))
  NEc1[j]<-length(which(aopt1-yobs==Ec[j]))
  NEc2[j]<-length(which(aopt2-yobs==Ec[j]))
}
plot(Ec,NEc/n,"l",sub="Fréquences des écarts de prévision",col="black",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(Ec,NEc1/n,"l",sub="Fréquences_coût1 des écarts de prévision",col="red",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
plot(Ec,NEc2/n,"l",sub="Fréquences_coût2 des écarts de prévision",col="green",lwd=6)
grid(nx=NULL,ny=NULL,lty=6)
MoyEcartClimart<-matrix(data = c(NEc/n,NEc1/n,NEc2/n),3,5,byrow=TRUE)
print("Fréquences moyennes des écarts de prévision")
print(MoyEcartClimart)
print("Briers: W111 W151  W511")
print(c(BW,BW1,BW2))
print("Moyennes quadratiques de ces écarts")
print(c(B,B1,B2),digits=3)
```

On rapporte ici pour comparaison les Briers CEP et les moyennes quadratiques des écarts de prévisions terminales qui corroborent les graphes de fréquences de ces écarts 
"Briers: W111 W151  W511"
[1] 0.1751532 0.5130832 0.5078628
Les différences entre modèles en termes de Briers globaux sont encore systématiques en faveur de E1 mais les différences restent faibles.
Par contre les moyennes quadratiques sont plus sensibles mais ce sont les fréquences des écarts de prévision qui apparaissent plus parlantes avec notamment un net meilleur centrage des écarts autour de 0.

Au final temporaire on voit combien les différences certaines sont peu marquées en termes de scores de Brier même dissymétriques. Peut être aurions nous intérèt à monter le nombre de classes jusqu'a 10 par exemple (cas que nous avons pris pour le dia)

##FIN TEMPORAIRE DES COMPARAISONS

Pour la suite, on a seulement refait pour l'instant l'inference par Jags des modèles EEMOS et BFS_E2 (2 pivôts) d'Eric faits dans "EssaiTempNormalEch2" mais nous comptons achever l'analyse "complète??" pour ces deux modèles.

###---------------------

# Conclusions temporaires de JB:

J'ai préfère abandonner le notebook d'Eric pour le moment et utiliser un markdown à ma manière. Eric acceptes mes excuses le plus plates!

Je  ne suis pas en complet accord avec ses résultats malgré les très beaux graphes made by ggplot.
Ils ne correspondent pas tout à fait à mes suggestions malgré ce qu'en dit Eric: ses choix sont différents d'après son texte: 
 --On va travailler comme Krzysztofowicz en négligeant les incertitudes des hyper-pa. data.frame(Z2=rgamma(Repet,g,1), Z1=rnorm(Repet))--
 Ceci ne correspond pas aux priors conjugués naturels que je proposais notamment Z1=rnorm(repet,mean=0,sd=Z2^(-0.5)) et qui, d'après mes calculs justifiaient la  loi Student pour la moyenne connaissant la variance dans la NQT de l'analyse prédictive BFS.


Autre remarque: Eric dit traiter le modèle EMOS , --Stricto sensu, ce n'est pas le modèle EMOS mais celui ci simplifié en remplaçant l'ensemble des membres par leur moyenne-- En fait ce modèle d'EMOS d'Eric reprend la structure marginale de l'échangeabilité des ensembles et fait une hypothèse, qui peut  être acceptable selon BFS, de la partie prédictive. C'est aussi de l'analyse philosophique (au sens de Kadane) de la structure BFS et la comparaison des méthodes doit impérativement en tenir compte.

 Dans le genre de calculs basés sur le CRPS et les errements habituels de la littérature des ensembles, on oublie les avantages statistiques, notamment de parsimonie, des modèles échangeables. Eric ne traite pas d'ailleurs des erreurs d'échantillonnage. Le faut il si on veut être vraiment honnète envers ces modèles statistiques?
 
 En fait dans tous nos calculs on ne traite pas  le vrai problème opérationnel des prévisions adaptatives avec information partielle. Je suis sûr que la parsimonie des modèles échangeables devrait être déterminante à ce niveau.Seuls les imbéciles n'ont pas de doutes- ça j'en suis certain-comme disait Courteline. Conclusion les statisticiens ne sont pas des imbéciles mais il y a des exceptions. 













