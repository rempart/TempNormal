---
title: 'MainPrevitemp'
author: "Éric Parent & Jacques Bernier"
date: "1/03/2021"
output:
  html_notebook
---



# Chargement préalable des données et librairies nécessaires

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
# library(tidyselect)
# library(lubridate)
 library(R2jags)
 library(verification)
 library(GGally)
# library(MCMCpack)
 library(goftest)
# library(e1071)
# library(grid)
# library(kableExtra)
 library(ensembleBMA)
 library(scoringRules)
# library(Hmisc)
```


Les données journalières de températures sont fournies par EDF-DTG pour l' Ain à Vouglans. On dispose des 2 *data.frames* suivants: 

*  l' historique journalier sur la période 1953 à 2015 dans le *data.frame dhisto*, 

* ainsi que celui des "$50$ membres du Centre Européen de Prévision" pour les années 2005 à 2008 (4 ans avec échéance de 1 à 7 jours) puis de 2O11 à 1015 (5 ans pour des prévisions jusqu'à une échéance de 9 jours) à Vouglans dans le *data.frame dtout*.

```{r}
rm(list=ls())
# setwd("~/Documents/courbariaux/WORKLUC/TempEnsemblesNormal")
load("Ain@Vouglans.Rdata")
#load("Buech@Chambons.Rdata")
#load("Drac@Sautet.Rdata")
horizon=4
```

# Analyses de la climatologie

## Un coup d'oeil sur les données  historiques

Un comportement sûrement aberrant est observé en date du 2003-10-15, horsain d'un jour mais on enlèvera pour la suite l'année 2003 *complète* du fichier historique dhisto. 

```{r}
fig_clim<-dhisto %>% filter(Year!= 2003) %>% mutate(an=factor(Year)) %>%
ggplot(aes(x = Calendaire, y= T)) + geom_point(aes( color = an),alpha=0.5, shape ='.', show.legend = FALSE)+geom_smooth(method = "gam",formula = y ~ s(x, bs="cs"))+labs(x=' Calendar days', y='Temperatures', title="Climatology at Vouglans station")
fig_clim
```

## Changement climatique

Le changement climatique est de l'ordre de 1.9 °C pour 100 ans. On considère par la suite les températures rapportées à la dernière année, l'année 2015

```{r}
fig_ChangeClim<-dhisto %>% group_by(Year) %>% summarise(T=mean(T)) %>% ggplot()+
  aes(x=Year,y=T)+geom_point()+geom_smooth(method="lm")+#geom_smooth(method="gam")+
  labs(y="Mean Annual Temperature",title="Temperature warming")
fig_ChangeClim

ChangementClim=lm(T~Year, data=dhisto %>% group_by(Year) %>% summarise(T=mean(T)) ) 

dhisto %>% group_by(Year) %>% summarise(T=sd(T)) %>% ggplot()+
  aes(x=Year,y=T)+geom_point()+geom_smooth(method="lm")+#+geom_smooth(method="gam")+
  labs(y="Temperature Annual Standard Deviation")
grid.arrange(fig_clim,fig_ChangeClim)
```



## Calcul d'une température moyenne journalière de référence et Première analyse des données

On va alors construire une température moyenne de réference lissée pour chaque jour calendaire de l'année. Pour construire ces estimateurs lissés périodiques, on *régresse*, en fonction des 4 premières harmoniques, les températures interannuelles sur la base calendaire moyenne après élimination des années bissextiles. Les températures désaisonnalisées sont appelées *T_ecart*. On ne procède pas à la regression sur les variances mais à un classement par saison. Par défaut on en distingue 2(hiver: décembre à avril, été:mai à novembre).

 On doit noter que le rejet "bissextile" par la variable calendaire=366 rejette en fait la dernière observation de chaque année bissextile c'est à dire le *31 décembre*. Nous avons conservé ceci pour le calcul des valeurs climatiques ajustées (T_ref_lis)

```{r}
histo_ref<- dhisto  %>% filter(Year!= 2003, Calendaire != 366)
base<-function(t){
  cbind(sin(2*pi*t/365),cos(2*pi*t/365),
        sin(2*pi*2*t/365),cos(2*pi*2*t/365),
        sin(2*pi*3*t/365),cos(2*pi*3*t/365),
        sin(2*pi*4*t/365),cos(2*pi*4*t/365))}
modlin<-lm(T~ 1+base(Calendaire)+Year, data=histo_ref)
histo_ref<-histo_ref %>% mutate(T_ref_lis=modlin$fitted.values,T_ecart=T-T_ref_lis) 
# ---Calcul moyennes et ecart-types calendaires
histo_ref %>% group_by(Calendaire) %>% summarise(MTecal=mean(T_ecart),SDTecal=sd(T_ecart)) -> Tecal
T_ecart<-histo_ref$T_ecart
N<-length(T_ecart)
MTE<-mean(T_ecart)
SDTE<-sd(T_ecart)
pU_ecart<-pnorm((T_ecart-MTE)/SDTE,0,1)
#--------
dg0<- ggplot(histo_ref, aes(x = T_ecart)) + 
    geom_histogram(aes(y =..density..),colour = "black", fill = "white") +
stat_function(fun = dnorm, args = list(mean = MTE, sd = SDTE),col="red",lwd=2)+ labs(x='Temperature Deviations', y='Empirical Density', title="Seasonally adjusted Temperature ")
#---------
tacf<-acf(T_ecart,lag.max=15,plot=FALSE)
btcaf <- with(tacf, data.frame(lag, acf))
dg4 <- ggplot(data=btcaf, mapping=aes(x=lag, y=acf))+labs(title = "Daily Autocorrelation") + geom_bar(stat = "identity", position = "identity")

histo_ref %>% ggplot(aes(x = 1:N, y= T_ecart)) + geom_point(shape='.')+labs(x='Days', y='Deviations', title="Daily deviations time series") -> dg1

histo_ref %>% mutate(Saison=ifelse(Month %in% c(4:10), 1,0)) %>% dplyr::group_by(Saison) %>% mutate(SaisonSDT=sd(T_ecart),SaisonMT=mean(T_ecart)) %>% dplyr::ungroup() %>% as.data.frame() %>% dplyr::group_by(Calendaire) %>% dplyr::summarize( SDTecal=sd(T_ecart), MTecal=mean(T_ecart), SaisonSDT=mean(SaisonSDT),SaisonMT=mean(SaisonMT)  )->Tecaldf

Tecaldf %>% ggplot(aes(x = Calendaire, y= MTecal)) + geom_point()+geom_line()+geom_line(aes(x = Calendaire, y= SaisonMT), color='red', size=1)+labs(x='Calendar days', y='Mean Deviations ', title="Interannual Means for deviations ") -> dg2
Tecaldf %>% ggplot(aes(x = Calendaire, y= SDTecal)) + geom_point()+geom_line()+geom_line(aes(x = Calendaire, y= SaisonSDT), color='red', size=2)+labs(x='Calendar days', y='Standard Deviations', title="Interannual Sd of Temperature") -> dg3

grid.arrange(dg1, dg0, dg3, dg4, ncol=2, nrow =2)


```
*T_ecart* est la variable historique complète 1953-2015 (privée de 2003) désaisonnalisée (en moyenne), ici sans distinction de saison.
On notera la forte autocorrélation journalière ainsi que la variation calendaire des écart-types journaliers résiduels.


# Etude marginale des membres de l'ensemble
```{r}
YX<-left_join(dtout , histo_ref) %>% 
  dplyr::select(-Qobs,-PS)  %>% 
mutate(Xbar=rowMeans(dplyr::select(.,starts_with("Run"))),
             V2=apply(dplyr::select(.,starts_with("Run")),1,var)) %>% 
filter(!is.na(Xbar+V2+T+Obs)) 
#sum(YX$T!=YX$Obs)
#YX %>% glimpse
YX %>% filter(Year==2005, Calendaire %in% 190:(213), Echeance==4) %>% 
  dplyr::select(Date,T,Xbar,V2) %>% 
  mutate(ymin=Xbar-2*sqrt(V2),ymax=Xbar+2*sqrt(V2)) %>% 
  ggplot(aes(x=Date))+geom_line(aes(y=Xbar))+geom_point(aes(y=T), size=2, col="red")+
  geom_ribbon(mapping = aes(ymin=ymin,ymax=ymax), alpha=0.3, fill="grey")+
  labs( y="Temperature")+theme(legend.position=NULL) 

regul <- function(x) (x - YX$T_ref_lis)
YX %>%  mutate_at(vars(matches("Run")),regul) %>% 
  mutate_at(c("T","Xbar"),regul) %>% filter(Echeance==4) %>% 
dplyr::select(T,Xbar,starts_with("Run")) %>%
  cor()->cc
mean(cc[2,-(1:2)])

```
## Création de la base de données de travail apprentissage et validation


```{r}
ete<-c(5:11)
d<-YX %>% filter(Echeance==horizon, Month %in% ete) %>% dplyr::select(!starts_with("Run"),-Echeance) %>% mutate(y=T_ecart, x=Xbar-T_ref_lis, v2=V2, jeu=ifelse(Year<2010, yes="apprentissage",no="test")) %>% dplyr::select(-T,-T_ecart,-Xbar,-V2)
```

## Calage de la marge de x
```{r}
calage<-d %>% filter(jeu=="apprentissage")
S=50
#---------------------
model2pivots <- "
model{
demiddl<- (S-1)/2
# priors vagues
alpha ~ dunif(-5,5)
beta ~ dunif(0.01,20)
lambda ~ dgamma(0.01,0.01)
g ~ dgamma(0.1,0.1)
# latentes
for (t in 1:N) {Z2[t]~ dgamma(g,1)
                Z1[t] ~ dnorm(0,Z2[t]) #la precision est Z2
                
# Observations
                moy[t]<-alpha+beta*Z1[t]
                preci[t]<-Z2[t]*S/lambda/lambda
                xbar[t] ~ dnorm(moy[t],preci[t]) 
                b[t]<-demiddl/lambda/lambda*Z2[t]
                v2[t] ~ dgamma(demiddl,b[t])
                }
}
"
bugsdata<-list(xbar=calage$x,
             v2=calage$v2,
             N=length(calage$v2),
             S=S)
n.chains<-3
n.iter<-5000*10
n.burn<-5000*2
n.thin<- 10

inits1<-list(alpha=.1,beta=6,lambda=1, g=2)
inits2<-list(alpha=-.1,beta=5,lambda=1.1, g=3)
inits3<-list(alpha=.1,beta=4,lambda= 1.2, g=2)

if(!file.exists("outx.RData")) {
modele <- jags.model(file=textConnection(model2pivots), data=bugsdata, 
                    inits=list(inits1, inits2,inits3),
                     n.chains=n.chains, quiet=FALSE)
update(modele, n.iter=n.burn)

variable.names=c("alpha","beta","lambda","g")
out <- coda.samples(model=modele,                                       variable.names=variable.names, 
                    n.iter=n.iter,thin=n.thin)
save(out,file = "outx.RData")
                                }
load("outx.RData")
STAT<-summary(out)
```

On peut regarder la dispersion de ces évaluations bayésiennes des paramètres de la marginale de $X$
```{r}
gelman.plot(out)
out123<-rbind(purrr::pluck(out,1),
              purrr::pluck(out,2),
              purrr::pluck(out,3))%>% 
  as.data.frame()
out123 %>%   
  gather(param, value) %>% 
  ggplot(aes_string(x="value")) +
  geom_density(alpha=0.5,fill='blue') +
  facet_wrap(param~., scales = "free")

means123<-apply(out123,2,mean)
alpha_hat=means123[1]
beta_hat=means123[2]
g_hat=means123[3]
lambda_hat=means123[4]

ggpairs(out123)
#knitr::kable(STAT$statistics, format="latex", digits=2)

```


## Examen de la marginale en X
```{r examMarginaleX, message=FALSE, warning=FALSE}
k= as.numeric(sqrt((beta_hat^2+(lambda_hat^2)/S)/(lambda_hat^2)))
g1<-calage %>% mutate(Student=(x-alpha_hat)/k/sqrt(v2)) %>% ggplot(aes(x=Student))+geom_histogram(aes(y =..density..),colour = "black", fill = "white") +
stat_function(fun = dt, args = list(df =S-1),col="red",lwd=2)+ labs(x='Studentized Temperature ensemble', y='Empirical Density')+xlim(-4,4)

g2<-calage %>% mutate(Fisher=(g_hat)*(v2)/lambda_hat^2) %>% ggplot(aes(x=Fisher))+geom_histogram(aes(y =..density..),colour = "black", fill = "white") +
stat_function(fun = df, args = list(df1 =S-1, df2=2*g_hat),col="red",lwd=2)+ labs(x='Fisher-transformed variance of the ensemble', y='Empirical Density')+xlim(0,7)
grid.arrange(g1,g2)
```



## BFS predictif via jags
# Calculs formels

```{r child="MainPrevitempCondZ.Rmd"}
```


```{r}
modelpredictif2pivots <- "
model{
demiddl<- (S-1)/2
# priors vagues
mu ~ dunif(-10,10)
theta ~dunif(-40,40)
h ~ dgamma(0.01,0.01)


for (t in 1:N) {
# latentes
                Z2[t]~ dgamma(g,1)
                Z1[t] ~ dnorm(0,Z2[t]) #la precision est Z2
                
# Observations en X
                moyx[t]<-alpha+beta*Z1[t]
                precix[t]<-Z2[t]*S/lambda/lambda
                xbar[t] ~ dnorm(moyx[t],precix[t]) 
                b[t]<-demiddl/lambda/lambda*Z2[t]
                v2[t] ~ dgamma(demiddl,b[t])
                
# Observations en Y
                moyy[t]<-mu+theta*Z1[t]
                preciy[t]<-Z2[t]*h
                y[t] ~ dnorm(moyy[t],preciy[t]) 
               }
}

"
bugsdata<-list(xbar=calage$x,
             v2=calage$v2,
             N=length(calage$v2),
             S=50,
             alpha=alpha_hat,
             beta=beta_hat,
             g=g_hat,
             lambda=lambda_hat,
             #y= calage$y)
             y=(calage$y-mean(calage$y))/sd(calage$y))
n.chains<-3
n.iter<-5000*10
n.burn<-5000*2
n.thin<- 10

inits1<-list(mu=.5,theta=6,h=1)
inits2<-list(mu=.4,theta=5,h=1.1)
inits3<-list(mu=.2,theta=4,h= 1.2)

if(!file.exists("outyx.RData")) {
modele <- jags.model(file=textConnection(modelpredictif2pivots), data=bugsdata, inits=list(inits1, inits2,inits3),
                     n.chains=n.chains, quiet=FALSE)
update(modele, n.iter=n.burn)

variable.names=c("mu","theta","h")
out <- coda.samples(model=modele,                                       variable.names=variable.names, 
               n.iter=n.iter,thin=n.thin)
save(out,file = "outyx.RData") 
                                 }
load("outyx.RData")
STAT<-summary(out)

```

L'incertitude a posteriori
```{r}
gelman.plot(out)
out123<-rbind(purrr::pluck(out,1),
              purrr::pluck(out,2),
              purrr::pluck(out,3))%>% 
  as.data.frame()
out123 %>%   
  gather(param, value) %>% 
  ggplot(aes_string(x="value")) +
  geom_density(alpha=0.5,fill='blue') +
  facet_wrap(param~., scales = "free")

means123y<-apply(out123,2,mean)
h_hat_XY=means123y[1]
mu_hat_XY=means123y[2]
theta_hat_XY=means123y[3]

ggpairs(out123)

#knitr::kable(STAT$statistics, format="latex",dig=2)
```

On peut également mettre en place un algorithme EM des moindres carrés pour réaliser cette inférence

```{r}
InferParEM= function(alpha=alpha_hat, beta=beta_hat,lambda=lambda_hat,g=g_hat,
                     u= calage$x,
                     v=(calage$y-mean(calage$y)) / sd(calage$y),
                     #v=calage$y,
                     w=calage$v2){
NRM<-1000 
N=length(u)
Z1<-matrix(NA,N,NRM)
Z2<-matrix(NA,N,NRM)
for(r in 1:N) {
  Z2[r,]<-rgamma(NRM,g+25,rate=1+0.5*S*((S-1)*w[r]/(S*lambda^2)+
                                  (u[r]-alpha)^2/(lambda^2+S*beta^2)))
  Z1[r,]<-rnorm(NRM,S*beta*(u[r]-alpha)/(lambda^2+S*beta^2),
                lambda/sqrt(Z2[r,]*(lambda^2+S*beta^2)))
}
A<-apply(Z2,1,"mean")
B<-apply(Z2*Z1,1,"mean")
C<-apply(Z2*Z1^2,1,"mean")
D<-apply(Z1,1,"mean")
mu<-(sum(A*v)*sum(C)-sum(B*v)*sum(B))/(sum(A)*sum(C)-sum(B)^2)
teta<-(sum(B*v)*sum(A)-sum(A*v)*sum(B))/(sum(A)*sum(C)-sum(B)^2)
h<-N/sum(A*(v-mu)^2 -2*teta*B*(v-mu)+C*teta^2)
return(list(mu=mu,theta=teta,h=h, 
            Z1=D, Z2=A,
            ypred= mu+teta*D,
            spred= (h*A)^-0.5))}

ll=InferParEM()

h_hat=ll$h
mu_hat=ll$mu
theta_hat=ll$theta
mean(ll$spred)

data.frame(y=(calage$y-mean(calage$y)) / sd(calage$y),
           ypred= ll$ypred) %>%
  ggplot(aes(x=y, y=ypred))+ geom_point()+geom_abline(intercept=0, slope=1)

# means123y
data.frame(y=(calage$y-mean(calage$y)) / sd(calage$y),
           ypred= mu_hat_XY+theta_hat_XY*ll$Z1) %>%
  ggplot(aes(x=y, y=ypred))+ geom_point()+geom_abline(intercept=0, slope=1)

data.frame(y=(calage$y-mean(calage$y)) / sd(calage$y),
           Z1=ll$Z1, Z1theo= (calage$x-alpha_hat)*S*beta_hat/(S*beta_hat^2+lambda_hat^2)) %>%
  ggplot(aes(x=Z1, y=Z1theo))+ geom_point()+geom_abline(intercept=0, slope=1)

```
On peut finalement passer au programme BUGS les moyennes de $Z1|X$ et $Z2|X$
```{r}

modelpredictif2pivotsBis <- "
model{
# priors vagues
mu ~ dunif(-10,10)
theta ~dunif(-150,150)
h ~ dgamma(0.01,0.01)


for (t in 1:N) {
# Observations en Y
                moyy[t]<-mu+theta*Z1[t]
                preciy[t]<-Z2[t]*h
                y[t] ~ dnorm(moyy[t],preciy[t]) 
               }
}
"
bugsdata<-list(Z1=ll$Z1,
               Z2=ll$Z2,
              N=length(ll$Z1),
              y= (calage$y-mean(calage$y))/sd(calage$y)
              )
             
n.chains<-3
n.iter<-5000*10
n.burn<-5000*2
n.thin<- 10

inits1<-list(mu=.5,theta=60,h=1)
inits2<-list(mu=.4,theta=50,h=1.1)
inits3<-list(mu=.2,theta=-4,h= 1.2)

if(!file.exists("outyxbis.RData")) {
modele <- jags.model(file=textConnection(modelpredictif2pivotsBis), data=bugsdata, inits=list(inits1, inits2,inits3),
                     n.chains=n.chains, quiet=FALSE)
update(modele, n.iter=n.burn)
variable.names=c("mu","theta","h")
out <- coda.samples(model=modele,                                       variable.names=variable.names, 
               n.iter=n.iter,thin=n.thin)
save(out,file = "outyxbis.RData") 
                                 }
load("outyxbis.RData")
STAT<-summary(out)
STAT$statistics[,1]
h_bis=STAT$statistics[1,1]
mu_bis=STAT$statistics[2,1]
theta_bis=STAT$statistics[3,1]

gelman.plot(out)
ggmcmc::ggs_traceplot(ggmcmc::ggs(out))
ggmcmc::ggs_density(ggmcmc::ggs(out))
ggmcmc::ggs_pairs(ggmcmc::ggs(out))

```
```{r}
calage %>% mutate(Z1=ll$Z1,Z2=ll$Z2) %>% 
  mutate(ypred_jags = mu_hat_XY+theta_hat_XY*Z1,
             ypred_EM= mu_hat+theta_hat*Z1,
            ypred_meanZ1= mu_bis+theta_bis*Z1) %>% 
  dplyr::select(y,ypred_jags,ypred_EM, ypred_meanZ1) %>%     
  gather(-y,key=methode,value = prediction) %>% 
  ggplot(aes(x=as.numeric(scale(y)), y=prediction))+geom_point(aes(color=methode),size=0.5)+
  geom_abline(slope=1,intercept=0)+facet_wrap(~methode)+labs(x="Cible y centrée réduite")

calage %>% mutate(Z1=ll$Z1,Z2=ll$Z2) %>% 
  mutate(ypred= mu_hat+theta_hat*Z1,   
            spred= (h_hat*Z2)^-0.5,
         y=as.numeric(scale(y))) %>% 
  dplyr::select(y,ypred, spred) %>% 
  #ggplot(aes(x=y,y=ypred))+geom_point()+
  #geom_abline(slope=1,intercept=0)
filter(as.numeric(rownames(calage)) %in% sample(x=1:(length(calage$y)),size = 50, replace = F) ) %>% ggplot(aes(x=y, y=ypred))+
  geom_segment(aes(x=y,xend=y, y= ypred-2*spred, yend=ypred+2*spred))+
  geom_abline(aes(intercept=0, slope=1)) +geom_point(shape=19, color="red") +
  labs(x="Target y (centered & rescaled)", y="Prediction with 95% confidence band")



```


## Validation

On écrit une fonction de prédiction du BFS à 2 pivot

```{r}
validation<-d %>% filter(jeu=="test") %>% dplyr::select(-jeu)

previKRZ2pivot<- function(combien=1000,
                          u= validation$x, 
                          w=validation$v2,
                          alpha = alpha_hat,
                          beta = beta_hat,
                          lambda =lambda_hat,
                          g = g_hat,
                          mu=mu_hat,
                          theta=theta_hat,
                          h=h_hat){
NRM<-combien 
N=length(u)
Z1<-matrix(NA,N,NRM)
Z2<-matrix(NA,N,NRM)
CondYsachantX<-matrix(NA,N,NRM)
for(r in 1:N) {
  Z2[r,]<-rgamma(NRM,g+S/2,rate=1+S/2*((S-1)*w[r]/(S*lambda^2)+
                                     (u[r]-alpha)^2/(lambda^2+S*beta^2)))
  Z1[r,]<-rnorm(NRM,S*beta*(u[r]-alpha)/(lambda^2+S*beta^2),
                lambda/sqrt(Z2[r,]*(lambda^2+S*beta^2)))
  CondYsachantX[r,]<-mu+theta*Z1[r,]+(h*Z2[r,])^(-0.5)*rnorm(NRM)
}

return(list(meanKRZ=mu+theta*apply(Z1,1,"mean"), 
            sdKRZ=1/sqrt(h*apply(Z2,1,"mean")),
            meanKRZbis= apply(CondYsachantX,1,"mean"),
            sdKRZbis= apply(CondYsachantX,1,"sd")))
}

CondYsachantX = previKRZ2pivot()

#mean(crps(y = as.numeric(scale(validation$y)), family = "normal", mean = CondYsachantX$meanKRZ, sd = CondYsachantX$sdKRZ))
#mean(crps(y = as.numeric(scale(validation$y)), family = "normal", mean = CondYsachantX$meanKRZbis, sd = CondYsachantX$sdKRZbis))

lmbrut<-lm(y~x,data=calage %>% mutate(y=(y-mean(y))/sd(y)))
#(coef(lmbrut))

#var(lmbrut$residuals)^0.5

#mean(crps(y = as.numeric(scale(validation$y)), family = "normal", mean = (coef(lmbrut))[1]+ (coef(lmbrut)[2])*validation$x, sd = var(lmbrut$residuals)^0.5))

validation %>% mutate(Model="KrzBFS", MTE=CondYsachantX$meanKRZ, STDE= CondYsachantX$sdKRZ)->vkrz
validation %>% mutate(Model="Regres", MTE=(coef(lmbrut))[1]+ (coef(lmbrut)[2])*x, STDE= var(lmbrut$residuals)^0.5)->vreg
d_grouped2 <- rbind(vkrz,vreg) %>% as_tibble() %>% 
      group_by(Model,Year) %>%  nest() 
```


## Structure des données par analyse en composantes principales

Cette analyse est importante car elle permet un jugement sur l'hypothèse échangeable.

```{r}
Eas<-YX %>% filter(Echeance==horizon,Month %in% c(4,10) ) %>%  dplyr::select(contains("Run"))
#Eas=Eas-(YX %>% filter(Echeance==horizon,Month %in% c(4,10)) %>% pull(T_ref_lis))
S=dim(Eas)[2]
ACP<-princomp(Eas,cor=TRUE,scores=TRUE)
ACPfirst<-data.frame(qui=1:S,sdF=ACP$sdev,PoidsMembres=ACP$loadings[,1],
        MA=apply(Eas,2,"mean") , SdA=apply(Eas,2,"sd")) %>% 
  mutate(Inert = sdF*sdF/sum(sdF*sdF),
         InertBis=Inert*ifelse(qui==1,0,100))
dga<-ACPfirst %>% #filter(qui<10) %>%
  ggplot(aes(x=qui,y=Inert))+geom_bar(stat="identity")+
  geom_bar(aes(y=InertBis), stat="identity",fill="grey")+
  labs(y="Inertia",x="Order of Eigenvalues", title="(A): Scaled eigenvalues")

 dgb<- ACPfirst %>% #filter(qui<10) %>%
  ggplot(aes(x=qui,y=PoidsMembres))+geom_point()+geom_line()+ylim(0.135,0.15)+
 #+geom_bar(stat="identity")+
  labs(y="Weight in first PCA",x="Members", title="(B): Member Weights") 
 
  dgc<-ACPfirst %>% #filter(qui<10) %>%
  ggplot(aes(x=qui,y=MA))+geom_point()+geom_line()+ylim(10,11)+
  labs(y="Mean",x="Members", title="(C): Member Means") 
  
dgd<-ACPfirst %>% #filter(qui<10) %>%
  ggplot(aes(x=qui,y=SdA))+geom_point()+geom_line()+ylim(3,4.5)+
  labs(y="Standard deviation",x="Members", title="(D): Member Standard Deviations") 

grid.arrange(dga,dgb,dgc,dgd)

```

La première figure représente l'inertie des 10 premiers facteurs rangés par ordre de grandeur.La première composante pèse 96,3% de l'inertie totale. Pour faire apparaître les suivantes nous les avons multipliés par 100, en noir sur la figure. On voit le très grand poids de cette première composante.

Les figures suivantes donnent, pour la seconde, le poids de chacun des 50 membres dans l'expression de cette composante très dominante. Il est clair que ces poids sont très sensiblement égaux ce qui signifie que cette composante est très proche de la moyenne d'ensemble Xbar. Les dernières figures montrent que les moyennes marginales sur 2005-2009 de chaque membre sont assez semblables de même que les écart-types ce qui va dans le sens de l'hypothèse d'échangeabilité.

--Compte tenu de ces résultats et surtout de l'importance d'une seule composante, nous avons décider d'incorporer dans notre comparaison , le modèle échangeable simple à 1 pivot.--


# Données climatiques Tds (vecteur) et variables catégorisées clim. BT  ET Pcep (matrices 3 colonnes)


## Description des fonctions fittest et fitvalid

Pour diminuer l'effet des autocorrélations les statistiques et test sont calculés sur des sous-échantillons 1/N0 de valeurs de la variable traitée, appelée X en interne à la fonction. Il s'agit d'échantillons de "cibles de prevision" dont on veut tester la loi conditionnelle, à prédicteurs fixés. Pour les températures, ce sont généralement des lois normales. Ce sont ces sous échantillons, préalablement constitués qui sont introduits avec X. 

MTE et SDTE sont les moyennes et écart-types vectoriels, prédictifs calculés du vecteur X.
N0 est la taille initiale de l'échantillon.
m est le nombre de prédicteurs + 1 du modèle de prévision (est utilisé dans fitvalid)
On peut éventuellement modifier  ces paramètres de référence pour traiter certaines distributions préquentielles (au sens de Dawid).

```{r}
fittest<-function(X=rnorm(100), MTE=rep(0,100), SDTE=rep(1,100) ,N0=3,K=20) {
#X  observation, MTE et SDTE moyenne et ectype de la prevision probabiliste normale
N<-length(X)
NR<-5000
# 5000 répetitions par défaut du tirage a priori dans une Polya
#TTP<-matrix(NA,6,2)
GXp<-pnorm(X,MTE,SDTE)
ttpit<-cvm.test(GXp,"punif")
cvm<-ttpit[[1]]
p.cvm<- ttpit[[2]]        
#TTP[1,]<-c(ttpit[[1]],ttpit[[2]])
# test classique de Cramer Von Mises : estimation et (p-value).
Hpit<-hist(GXp,seq(0,1,1/K),plot=FALSE)
chit<-sum(((Hpit[[2]]-N/K)^2)/(N/K))
#TTP[2,]<-c(chit,1-pchisq(chit,K-1))
p.chit<-1-pchisq(chit,K-1)
# test du CHI2 sur la classification PIT (10 classes) avec la p-value correspondante.
Pdiri<-bmixture::rdirichlet(NR, alpha =rep((N+1)/K,K) )
Mnom<-matrix(NA,NR,K)
for(j in 1:NR){
 Mnom[j,]<-rmultinom(1,N,Pdiri[j,]) 
}
  Postpit<-apply(((Mnom-N/K)^2)/(N/K),1,"sum")
#TTP[3,]<- c(chit,length(which(Postpit>=chit))/NR)
  bayescredib<- length(which(Postpit>=chit))/NR
#Credibilité a posteriori du  CHI2, obtenue par simulation (Polya), à partir d'un prior uniforme sur les 10 classes (5000 répetitions par défaut)
#--------
LpX0n<-sum((dnorm(X,mean(X),sd(X), log=T)))/log(10)
LpXn<-sum((dnorm(X,MTE,SDTE, log=T)))/log(10)
 
#TTP[4,]<-c(LpXn,LpX0n)
# log10 de la vraisemblance et log10 du Rapport de Bayes par rapport au modèle de référence. Dans l'exemple la référence est identique d'ou la valeur 0 du log10 du RB.Il ne s'agit pas du BIC ou AIC car on suppose les paramètres connus exactement.
   liste= (list(chit=chit,p.chit=1-pchisq(chit,9), p.credib=bayescredib,
           LpXn=LpXn,LpX0n=LpX0n, cvm=cvm, p.cvm= p.cvm ))
   liste = map_dbl(liste,round,digits=3)
  return(liste)

#TTP[5,]<-c(mean(MTE),mean(SDTE))
# moyenne et ecart-type de l'échantillon testé
#TTP[6,]<-c(N,N0)
#taille de l'échantillon testé vis à vis de l'échantillon initial. Compte tenu de la forte autocorrélation (0.8) des températures, on a pris une observation sur 3 (par défaut) pour tous les tests dans cette première version.
#TTP<-round(TTP,4)
#return(list(Hpit,TTP))
} 

#-------  fin de fittest et début de fitvalid  -----------
# a compléter le vendredi 26 février 2021!!!!!!
fitvalid<-function(X=rnorm(100),mpred=rep(0,100), sdpred=rep(1,100), K=20, N0=3) {
brk0<-qnorm((1:K-1)/K,mean(X),sd(X))
brke<-c(max(min(X),brk0[1]),brk0[2:K],max(X))
#K=length(brke)-1
W=c(rep(1,K-1),5)
WM<-max(W)
N<-length(X)
Gpred<-pnorm(X,mpred,sdpred)
crps<-scoringRules::crps_norm(X,location = mpred, scale = sdpred)
Mcrps<-mean(crps) 
CVcrps=sd(crps)/Mcrps
#score propre CRPS continu classique (from scoringRules pkg)
Mlogs<-mean(scoringRules::logs_norm(X,location = mpred, scale = sdpred))
# score IGNorance ou LOGarithmique (from scoringRules pkg)
Y<-Ppred<-matrix(NA,N,K)
BRJ<-BRWJ<-PR0J<-BWoptJ<-BpJ<-rep(NA,N)
tbb<-c(qnorm(seq(1/K,(1-1/K),1/K),0,1))
for(j in 1:N){
  HG<-hist(Gpred[j],seq(0,1,1/K),plot=FALSE)
  Y[j,]<-HG[[2]]
  Ppred[j,]<-c(pnorm(tbb,mpred[j],sdpred[j])-pnorm(tbb,mpred[j],
                                                   sdpred[j]),1-pnorm(tbb[K-1],mpred[j],sdpred[j]))
BRJ[j]<-sum((Ppred[j,]-Y[j,])^2) 
BRWJ[j]<-sum(W*(Ppred[j,]-Y[j,])^2)
#Score de Brier sur K classes (formule PIT) symétrique et dissymetrique. La deuxieme prend en compte un coût W de pondérations Wi (i=1:10) qui transforme le score en regret (opportunity loss -au sens de Savage). Le cas traité par défaut (Wi=1 sauf W10=5) est équivalent à un cas de prévision binaire (voir Degroot et Fienberg) où l'évènement dommageable est la valeur de cible supérieure au quantile historique de prob. 0.90. 
PR0J[j]<-sum(Ppred[j,which(W>1)])
BWoptJ[j]<-WM*PR0J[j]*(1-PR0J[j])/(1-PR0J[j]+WM*PR0J[j])
BpJ[j]<-PR0J[j]*(1-PR0J[j])*(PR0J[j]+WM*(1-PR0J[j]))
#Dans ce dernier cas l'utilisateur de la prévision donnée par le prévisionniste, et qui subit ce dommage, peut utiliser une décision probabiliste optimale minimisant ce coût terminal. BWoptJ est le regret minimal et BpJ le regret, plus élevé résultant de l'utilisation de la probabilité du prévisionniste.
}
corr<-cor(X,mpred)
#if(sign==1) {corr=sqrt(mean(sdpred^2+(X-mpred)^2))/sd(X)}
Rrat<-1-corr^2

liste= list(ScoreCRPS=Mcrps,
                  ScoreIgnorance= Mlogs,
                  BrierSym=mean(BRJ),
                  BrierW=mean(BRWJ),
                  RegretMin=mean(BWoptJ),
                  Regret=mean(BpJ),
                  corr=corr,
                  ResidVar = 1- corr^2,
                  CVScoreCRPS=CVcrps)
liste = map_dbl(liste,round,digits=3)
return(liste)
}
```



```{r test functions}

d_grouped2 %>% 
      mutate(
      chi2tout= purrr::map(data,
                           ~{fittest(X=as.numeric(scale(.x$y)),MTE=.x$MTE,SDTE=.x$STDE)}),
      Chi2=purrr::map_dbl(chi2tout,1),
      p.Chi2=purrr::map_dbl(chi2tout,2),
      BayesKi=purrr::map_dbl(chi2tout,3),
      CramVM =purrr::map_dbl(chi2tout,6),
      p.Cram =purrr::map_dbl(chi2tout,7),
      LogLik=purrr::map_dbl(chi2tout,4),
      LogBF=purrr::map_dbl(chi2tout,5)
      ) %>% 
      dplyr::select(-chi2tout,-data) %>% 
   knitr::kable()

d_grouped2 %>% 
      mutate(fitvalidtout=purrr::map(
            data, ~{ fitvalid(X=as.numeric(scale(.x$y)),.x$MTE,.x$STDE) }
         ),
         CRPS = purrr::map_dbl(fitvalidtout,1),
         IGN = purrr::map_dbl(fitvalidtout,2),
         BrierSym = purrr::map_dbl(fitvalidtout,3),
         BrierW = purrr::map_dbl(fitvalidtout,4),
         RegretMin = purrr::map_dbl(fitvalidtout,5),
         Regret = purrr::map_dbl(fitvalidtout,6),
         corr = purrr::map_dbl(fitvalidtout,7),
         ResidVar = purrr::map_dbl(fitvalidtout,8)
      ) %>% 
      dplyr::select(-fitvalidtout,-data) %>% 
     # dplyr::select(CRPS,IGN,BrierSym, BrierW,RegretMin,Regret,corr,ResidVar) %>% 
      knitr::kable()
```


## Selection et Propriétés statistiques des échantillons sélectionnés

 Choix de saison et Consitution des tibbles de données sélectionnés saison apprentissage et validation

Les premiers résultats traitent de  l'échantillon d'appentissage avec quelques résultats de validations sur l'année 2012

Les data.frames ou matrices de base nécessaires sont maintenant construites
puis viendra ensuite le choix de l'échéance pour consituer les data.frames de calcul Tcala et TCALv (Apprentissage et Validation).

#### ECHANTILLONS  Saison, Apprentissage, Validation sélectionnéS
2 saisons :été: mois= 5,6,7,8,9,10,11)        hiver: mois=12,1,2,3,4 (hiver)
apprentissage: 2005 -2008
Validation (>2010): 2012


```{r}
valid<-2012
ete<-c(5:11)
histo_ref %>% mutate(Saison=if_else(Month %in% ete,1,2)) -> histo_ref
histo_ref%>% filter(Saison!=2,Year %in% c(2005,2006,2007,2008) ) ->histosa
dtout %>% filter(Calendaire != 366,Year %in% c(2005,2006,2007,2008) ) %>%  
mutate(Saison=if_else(Month %in% c(5:11),1,2), Xbar=rowMeans(dplyr::select(.,starts_with("Run"))),SDx=apply(dplyr::select(.,starts_with("Run")),1,sd)) -> dba
dba %>% filter(Saison!=2) ->dtoutsa
#--------
histo_ref%>% filter(Saison!=2,Year == valid) ->histosv
dtout %>% filter(Calendaire != 366,Year==valid) %>%  
mutate(Saison=if_else(Month %in% c(5:11),1,2), Xbar=rowMeans(dplyr::select(.,starts_with("Run"))),
    SDx=apply(dplyr::select(.,starts_with("Run")),1,sd)) -> dbv
dbv %>% filter(Saison!=2) ->dtoutsv
```

## Choix de l'Echeance pour l'Apprentissage

Le cas choisi par défaut est l'échéance 4
Ensuite on combine les deux tibbles: histos (données historiques) et dtoutba que l'on joint à Tcal0 pour obtenir par selection le tibble Tcala pour cette échéance en période d'apprentissage). 

--Le fichier de travail final d'apprentissage est donc Tcala.--

Pour tous les modèles d'ensemble la variable modélisée est donc **la variable température journalière T_cart**  de la sous période supposée stationnaire choisie

-- Parallélement on obtient --le fichier de validation Tcalv--, traité non systématiquement pour l'instant.

```{r}
ECHE<-4
dtoutsa%>%filter(Echeance==ECHE) -> dtoutap_eche 
histosa%>%filter(Year %in% c(2005,2006,2007,2008)) -> histosa
Tcala<-bind_cols(dtoutap_eche,histosa)
Tcala%>% filter(!is.na(Xbar))%>% mutate(T_ecart=T-T_ref_lis,Xbar=Xbar-T_ref_lis) -> Tcala
Tcala%>% dplyr::select(-Date1,-Year1,-Month1,-Calendaire1,-Saison1) -> Tcala
Eas<-as.matrix(Tcala[,c(4:53)])
deas<-dim(Eas)
dim(Tcala)
#---------
dtoutsv %>%filter(Echeance==ECHE) -> dtoutvp_eche 
histosv %>%filter(Year ==2012) -> histosv
Tcalv<-bind_cols(dtoutvp_eche,histosv)
Tcalv%>% filter(!is.na(Xbar))%>% mutate(T_ecart=T-T_ref_lis,Xbar=Xbar-T_ref_lis) -> Tcalv
Tcalv%>% dplyr::select(-Date1,-Year1,-Month1,-Calendaire1,-Saison1) -> Tcalv
dim(Tcalv)
#---------
#CHOIX Apprentissage ou Validation : On a pu choisir une année particulière avec Tcalv ou l'échantillon de calage Tcala
#Tcalv -> Tcal
Tcala -> Tcal
head(Tcal)
```




# Première Application: données d'apprentissage

## 1 - Analyse statistique de la période d'apprentissage (avec fittest())

On rapelle que le traitement est fait sur un sous échantillon 1/3 (instruction: Tds<-Tds0[seq(1,N0,3)]) pour éliminer (a priori) l'effet des autocorellations.

NB: mes difficultés tigyversitaires m'ont contraintes à ne pa utiliser *kable* pour l'instant.



```{r}
histo_ref%>% filter(Saison!=2) ->histo_1
T_ecart1<-as.numeric(histo_1[,9],narm=FALSE)
N0<-length(T_ecart1)
T_ecart1<-T_ecart1[seq(1,N0,3)]
HC<-hist(T_ecart1,50,right=FALSE,plot=FALSE)
N<-length(T_ecart1) 
MT1<-rep(mean(T_ecart1),N)
SDT1<-rep(sd(T_ecart1),N)
TT1<-fittest(T_ecart1,MT1,SDT1,N0)
#--------
d0<-as.data.frame(T_ecart1)
ggplot(d0, aes(x = T_ecart1)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill = "white") +
stat_function(fun = dnorm, args = list(mean = mean(T_ecart1), sd = sd(T_ecart1)),col="red",lwd=5) 
#---------
dgP0 <- TT1[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
dtt<-TT1[[2]]
TTtab1<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm", "Xbar_SD","tailles",dtt,rep(NA,12)),6,3))
kable(TTtab1)
```
Il s'agit ici du fichier historique complet pour l'été
les log vraisemblances sont égales car la distribution de reférence est prise identique (log vraisemblance en V3). Elles seront utiles au final pour comparer les rapports de Bayes (critère de Raftery et Kass.)
Globalement les ajustements normaux et PIT sons bons malgré l'autocorrelation résiduelle (0.50)

On notera la faible p.value du test du CHI2, comportement habituel normal des tests classiques pour de très grands échantillons, rectifié par la crédibilité.

## Application des tests sur l'échantillon d'apprentissage

Ci dessous on sort les propriétés statistiques de la saison, historique complète, ici mai-novembre, sélectionnée sur la periode d'apprentissage 2005-2008.


```{r}
# *T_ecarta est le vecteur d'Ecarts de températures d'apprentissage* 
T_ecarta<-as.numeric(Tcal[,64],narm=FALSE)
N0<-length(T_ecarta)
Tds<-T_ecarta[seq(1,N0,3)]
N<-length(Tds)
MY<-rep(mean(Tds),N)
SdY<-rep(sd(Tds),N)
#--------
ggplot(Tcal, aes(x = T_ecart)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill = "white") +
stat_function(fun = dnorm, args = list(mean = mean(Tds), sd = sd(Tds)),col="red",lwd=5)
#---------
# Les tests sont appliqués à un sous echantillon 1/3 par défaut
TTas<-(fittest(Tds,MY,SdY,N0))
dgP0 <- TTas[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
#---------
TTtab<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm", "Xbar_SD","tailles",TTas[[2]],rep(NA,12)),6,3))
kable(TTtab)
```
Il s'agit ici de la période d'appentissage du fichier "dtout" (2005-2015) des ensembles après élimination des NA de celui ci.
Quel que soit la méthode de test (frequentiste ou bayesien), le modèle normal est acceptable pour ces données de températures, à la limite pour le CHI2 fréquentiste (284 jours), comme pour l'échantillon complet. Ce résultat est nettement contredit par le Cramer Von Mises et la credibilité bayesienne du CHI2, tous deux acceptables. De fait la tendance qu'ont les tests frequentistes au rejet des hypothèses testées pour de très grands échantillons est un phénomène classique.

On acceptera donc l'hypothèse bayesienne pour la suite. 

## 2 - Validation par ACP de l'échangeabilité des ensembles en apprentissage

```{r}
deas<-dim(Eas)
Eacp<-Eas[seq(1,deas[1],3),]
nn<-dim(Eacp)
S<-nn[2]
MA<-apply(Eacp,2,"mean")
SdA<-apply(Eacp,2,"sd")
ACP<-princomp(Eacp,cor=TRUE,scores=TRUE)
sdF<-ACP[[1]]
cdF<-ACP[[2]]
vdF<-ACP[[6]]
varcum<-cumsum(sdF*sdF)/sum(sdF*sdF)
Inert<-sdF*sdF/sum(sdF*sdF)
coef<-c(1 ,rep(100,9))
print(c("Inertie maximale  :" , Inert[1]))
print(c(deas[[1]],nn))
#--------
layout(matrix(c(1,2,3,4),2,2))
par(bg="grey90")
plot(1:10,Inert[1:10], "l",col="red",lwd=5, main="inerties x 100 des rangs 2:10 en noir")
lines(1:10,coef*Inert[1:10], "l",col="black",lwd=5)
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,cdF[,1],"l",lwd=3,col="red",bg="gray",main="poids des membres dans 1er facteur")
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,MA,"l",lwd=3,main="Moyennes des membres d'ensemble")
grid(nx=NULL,ny=NULL,lty=6)
plot(1:S,SdA,"l",lwd=3,main="Ecart-types des membres d'ensemble")
grid(nx=NULL,ny=NULL,lty=6)
```

--Compte tenu de ces résultats et surtout de l'importance d'une seule composante, nous avons décider d'incorporer dans notre comparaison , le modèle échangeable simple à 1 pivôt.--


#--------------------------

# Vérification du modèle CEP en apprentissage (et validation)

Rappelons que les prévisions probabilistes journalières CEP seront supposées normales de moyennes MTcep et écarts types SDTcep (d'après Eric).

Apprentissage (SUR 4 ANS)
Validation (sur 1 AN)

## Statistiques CEP sur apprentissage et Tests.

Rappelons que la structure BFS complète applique Bayes en phase prédictive à partir d'un prior climatique ce qui assure un bon calibrage des prévisions. Dans la suite nous ne ferons l'inference directe du modèle conditionnel de la predictive que sur les cibles des périodes d'apprentissage et validation ce qui permet une "validation prequentielle partielle" pour autant que ces périodes soient représentatives. Pour l'instant nous n'avons pas fait d'efforts plus particulier pour la "référence" climatique historique (identifiée à la période d'apprentissage 2005-2008 pour l'instant) 

Les deux premiers chunks CEP (concernent cette période d'apprentissage)

```{r}
Tds<-as.numeric(Tcal[,64],narm=FALSE)
N0<-length(Tds)
X<-Tds[seq(1,N0,3)]
N<-length(X)
MY<-mean(X)
SdY<-sd(X)
MTcep<-as.numeric(Tcal[,58],na.rm=FALSE)
SDTcep<-as.numeric(Tcal[,59],na.rm=FALSE)
mtcep<-MTcep[seq(1,N0,3)]
sdtcep<-SDTcep[seq(1,N0,3)]
Tred<-(X-mtcep)/sdtcep
dfTred<-dnorm(Tred,0,1)
# Inference et tests ------
TTacep<-fittest(X,mtcep,sdtcep,N0)
ggplot(as.data.frame(Tred), aes(x = Tred)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill = "white") +
stat_function(fun = dnorm, args = list(mean = MY, sd = SdY),col="red",lwd=2)
dgP0 <- TTacep[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
print("Distribution PIT")
print(matrix(c("classes",seq(0,0.9,0.1),"frequences",dgP0[[2]],"Unif",rep(N/10,10)),11,3))
TTtabcep<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm","Xbar_SD","tailles",TTacep[[2]]),6,3))
#----------Validation
N0<-length(Tds)
n0=N0
W<-c(rep(1,9),5)
vcep<-fitvalid(X,mtcep, sdtcep,N0,W,1)
Ttabcepv<-as.data.frame(matrix(c("CRPS_IGN","BRIER.B_BW","BRIERW.OPT_SYM","CORR_mult",
"tailles",vcep[[1]]),5,3))
PR0W<-vcep[[2]]
N<-length(X)
dg<-as.data.frame(matrix(c(X,mtcep,sdtcep,PR0W),length(X),4))
dg%>% ggplot(aes(x=1:N))+geom_ribbon(aes(ymin=mtcep-1.64*sdtcep,ymax=mtcep+1.64*sdtcep),color="black")+ geom_path(aes(y=X))+geom_point(aes(y=X),color="red", lwd=2)+ggtitle("valeur et cep")
kable(TTtabcep)
kable(Ttabcepv)
```

Rappelons le principe de la vérification ici. Le vecteur soumis aux tests est le vecteur de la cible **observée** sur l'apprentissage. En utilisant la  transformation Tred= (X-mtcep)/sdcep on devrait avoir une variable normale centrée, réduite (courbe rouge) alors que l'histogramme présente une dispersion nettement inférieure. C'est dire que la méthode CEP donne un poids trop fort aux quantiles extrèmes, résultat confirmé par le diagramme PIT et les tests statistiques très significatifs correspondants. 

En termes de validation prédictive (fitvalid()), on notera la valeur du crps continu=0.84 et celle du brier=1.12.
En ce qui concerne la prevision binaire terminale le risque quadratique pondéré associé (en termes de théorie de la décision) de la prévision cep est 50% supérieur à l'optimum.

-- C'est de fait les calculs CORR_mult(ligne 4) qui sont les plus significatifs. Il s'agit de l'adaptation au cas de variances variables, de la "CORRELATION MULTIPLE CIBLE-PREDICTEURS", validation classique des modèles de régression statistique. Ici corr. est égal au niveau faible de 0.50, assez voisin de la corrélation simple avec chaque membres individuel.--

Tous ces résultats sont très semblables avec l'échantillon 1/5.



## Echantillon de validation 2012 - Applcation de fittest et fitvalid

V1                V2             V3
CRAMERVM	        0.6096	       0.0209		
CHI2_probab	      31.9577	       0.0002	
CHI2_credib	      31.9577  	     0.0626		
logRbayesNorm	   -72.0158	      -81.4541		
Xbar_SD	          0.8679	       1.0256		
tailles	          71	           212

CRPS_IGN	        0.9189	       2.3355	
BRIER.B_BW	      1.1139	       2.4709	
BRIERW.OPT_SYM	  0.1448	       0.2299	
CORR_mult	        0.5662	       >0.9999		


L'échantillon est réduit ici à 71 jours. On note la médiocre qualité sinon le rejet du modèle par les tests alors que le crps apparait voisin de celui de l'échantillon d'apprentissage de même que le Brier, encore la faible sensibilité de ce critère **universel**.




# Modèle Gamma-Normal à 1 pivot (échangeable_BFS)

## - 1 Inference



```{r}
Tcal %>% filter( !is.na(Calendaire)) %>% 
 mutate(theta=T_ecart,xbar=Xbar, v2=SDx^2,dates=Date) %>%   filter(!is.na(theta),
          !is.na(xbar),!is.na(v2)) -> learning_sample
learning_sample %>%  dplyr::select(theta,xbar,v2,dates) -> apprentissage0
da0<-dim(apprentissage0)
N0<-da0[[1]]
apprentissage<-apprentissage0[seq(1,N0,3),]
y<-apprentissage[,1]
Xbar<-apprentissage[,2]
V2<-apprentissage[,3]
# L'inference et les tests sont appliqués à un sous echantillon 1/3 par défaut
# notations par défaut
X<-y
N<-length(y)
MEy<-mean(y)
Sdy<-sd(y)
h<-(S-1)/(S*mean(V2))
he<-(S-1)/(S*V2)
mu<-mean(Xbar)
lambda2<-var(Xbar)-h/S
#-----De phase 1 à phase 2. la NQT --> v.a. N(0,1): on prend y  en fonction de U centrée réduite ----- 
#U<-he*(Xbar-mu)
U<-h*(Xbar-mu)
lmyu<-lm(y~U)
para<-coefficients(lmyu)
Yp<-fitted.values(lmyu)
corr<-cor(y,U)
# Paramètres prédictifs (indice p) A+BU et C ECART-type-------
A<-para[[1]]
B<-para[[2]]
C<-sd(y-Yp)
mvp<-A+B*U
sdvp<-rep(C,N)
Yrp<-(y-mvp)/sdvp
Gvp<-pnorm(y,mvp,sdvp)
HYrp <-hist(Yrp,50,plot=FALSE)
dy<-HYrp[[3]]
ay<-HYrp[[4]]
layout(matrix(c(1,2,3,4),2,2))
par(bg="grey90")
plot(ay,dy,"h",main="histogramme de la cible")
lines(ay,dnorm(ay,MEy,Sdy),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
ecart<-y-Yp
plot(1:N,ecart,"h",main="Chronologie des écarts de prevision")
grid(nx=NULL,ny=NULL,lty=6)
plot(U,X,"p",main="regression cible-predicteur v.a réduite")
lines(U,mvp,"l",col="red")
grid(nx=NULL,ny=NULL,lty=6)
HER<-hist(Yrp,50,plot=FALSE)
der<-HER[[3]]
er<-HER[[4]]
plot(er,der,"h",main="Histogramme Ecar ts prédictifs réduits")
lines(er,dnorm(er,0,1),"l",col="red",lwd=5)
grid(nx=NULL,ny=NULL,lty=6)
print("correlation pivot-cible")
print(corr)
print(" Paramètres de la regression")
print(c(A,B,C),digits=4)
```

On notera le bon coefficient de correlation 0.92 avec la cible (0.91 avec l'échantillon 1/5) et les bons accords des histogrammes et la distribution normale selon les aspects marginaux et conditionnels.


**Remarque importante**: Nous avons essayé d'utiliser la température initiale du jour de prévision comme second prédicteur, --cela n'a pas donné d'amélioration en termes de précision--
Ce non-résultat corrobore de fait l'interprètation d'Eric comme quoi --l'ensemble X_ts (s=1:50) est, à t fixé, un résumé exhaustif de toute l'information nécessaire à la prévision,-- Y COMPRIS DONC les informations sur les conditions initiales.


## -2: Vérification de E1 en apprentissage ou validation


```{r}
mvp<-A+B*U

sdvp<-rep(C,N)
Yrp<-(y-mvp)/sdvp
dfXp<-dnorm(Yrp,0,1)
TTaX1<-fittest(y,mvp,sdvp,N0)
X<-y
ggplot(as.data.frame(X), aes(x = X)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill ="white") +
stat_function(fun = dnorm, args = list(mean = MEy, sd = Sdy),col="red",lwd=2)
dgP0 <- TTaX1[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
print("Distribution PIT")
print(matrix(c("classes",seq(0,0.9,0.1),"frequences",dgP0[[2]],"Unif",rep(N/10,10)),11,3))
TTtabX1<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm","Xbar_SD","tailles",TTaX1[[2]]),6,3))
#----------
W<-c(rep(1,9),5)
vcep<-fitvalid(X,mvp, sdvp,N0,W,0)
TtabX1v<-as.data.frame(matrix(c("CRPS_IGN","BRIER.B_BW","BRIERW.OPT_SYM.","CORR_mult","tailles",vcep[[1]]),5,3))
mpred0<-mvp
sdpred0<-sdvp
PR0W<-vcep[[2]]
N<-length(X)
dg<-as.data.frame(matrix(c(X,mpred0,sdpred0,PR0W),length(X),4))
dg%>% ggplot(aes(x=1:N))+geom_ribbon(aes(ymin=mpred0-1.64*sdpred0,ymax=mpred0+1.64*sdpred0),color="black")+ geom_path(aes(y=X))+geom_point(aes(y=X),color="red", lwd=2)+ggtitle("cible_rouge et Echangeable1_90%")
kable(TTtabX1)
kable(TtabX1v)
```

Le Cramer Von Mises est très bon, et les resultats sont sensiblement comparables avec le CHI2 classique (elle était acceptable avec p-value=0.26 pour 1/5)
On notera la **faible sensibilité** des scores CRPS ET Brier même par rapport aux résultats CEP. Les valeurs oscillent entre 0.80 et 0.91.

Ainsi les tests statistiques associés, Le Cramer Von mises aussi bien que l'histogramme PIT (fontion fittest) confirment la bonne qualité relative de la methode échangeable E1.

## Echantillon de validation 2012
Sur cet échantillon de 71 unités la corrélation cible-pivôt est :0.88.

Les résultats des test sont:

V1                V2             V3
CRAMERVM	        0.0678	       0.7666		
CHI2_probab	      5.7606	       0.7636	
CHI2_credib	      5.7606	       0.9698		
logRbayesNorm	   -57.9586	      -81.4541		
Xbar_SD	          0.9626	       1.5964		
tailles	          71	           212


CRPS_IGN	         0.8867	        1.8796		
BRIER.B_BW	       1.2838	        2.7009		
BRIERW.OPT_SYM.	   0.2114	        0.3325		
CORR_mult	         0.884      	  0
Encore une fois la très faible sensibilité du CRPS apparait. Sur cet échantillon de validation particulier (à un été) la corrélation multiple 0.88 est assez diminuée par rapport à l'apprentissage.

Nous devons signaler que le calcul du CRPS est directement issu du package R ScoringRules alors que les Briers résultent d'un calcul personnel pour être étendu au cas dissymétrique.

### -------

# ESSAIS de plusieurs modèles linéaires prédictifs généralisés

On peut essayer chaque cas (1 ou 2 ou 3) en copiant-collant les lignes respective de codes ci dessous au début du chunk suivant:

## 1 -Modèle linéaire sur ensemble E50 des 50 membres(sans modélè marginale des moyennes).

apprenti<-apprentissage
deas<-dim(Eas)
x<-Eas[seq(1,deas[1],3),]

## 2 - ensemble réduit à 3 prédicteurs: moyenne et 2 quantiles pour chaque jour (quantiles réduits -2,+2 par défaut)

apprentissage%>%  
mutate(Q3=xbar+2*sqrt(V2),Q1=xbar-2*sqrt(V2)) %>% filter(!is.na(theta),!is.na(xbar),!is.na(v2)) %>% dplyr::select(xbar,Q1,Q3) -> apprenti
x<-as.matrix(apprenti)

## 3 - ensemble réduit à la moyenne studentisée STXbar=(Xbar-mean(Xbar))*sqrt(S/V2) (en prélude au modèle à 2 pivôts et suite à ma première suggestion)

apprentissage %>%  
mutate(Q=(xbar-mean(xbar))*sqrt(S/V2)) %>%   
 dplyr::select(theta,xbar,Q ) %>%  filter(!is.na(theta),!is.na(xbar),!is.na(V2))-> apprenti
x<-apprenti$Q[seq(1,N,3)]


Rappelons que V2, dépendant de t, est la variance de chaque ensemble-échantillon. 

## INFERENCE

```{r}
apprentissage %>%  
mutate(Q=(xbar-mean(xbar))*sqrt(S/V2)) %>%   
 dplyr::select(theta,xbar,Q ) %>%  filter(!is.na(theta),!is.na(xbar),!is.na(V2))-> apprenti
x<-apprenti$Q
# -----------
da<-dim(apprenti)
N0<-da[[1]]
y<-apprentissage[,1]
N<-length(y)
MEy<-mean(y)
Sdy<-sd(y)
# -----------
lmpy<-lm(y~x)
para<-coefficients(lmpy)
Yp<-fitted.values(lmpy)
corr<-cor(y,Yp)
# Paramètres prédictifs (indice p) -------
A<-para[1]
B<-para[2:length(para)+1]
C<-sd(y-Yp)
mvp<-Yp
sdvp<-rep(C,N)
Yrp<-(y-mvp)/sdvp
Gvp<-pnorm(y,mvp,sdvp)
HYrp <-hist(Yrp,50,plot=FALSE)
dy<-HYrp[[3]]
ay<-HYrp[[4]]
layout(matrix(c(1,2,3,4),2,2))
par(bg="grey90")
plot(ay,dy,"h",main="histogramme de la cible")
lines(ay,dnorm(ay,MEy,Sdy),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
Hp<-hist(Yp,50,plot=FALSE)
dp<-Hp[[3]]
ap<-Hp[[4]]
plot(ap,dp,"h",main="histogramme du Predictif")
lines(ap,dnorm(ap,mean(Yp),sd(Yp)),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
plot(Yp,y,"p",main="regression cible-predicteur")
lines(Yp,Yp,"l",col="red")
grid(nx=NULL,ny=NULL,lty=6)
plot(1:N,y-Yp,"h",main="Chronologie des écarts de prevision")
grid(nx=NULL,ny=NULL,lty=6)
print(c("cor. pivot-cible",corr))
print(c("Ecart-type predictif",C))
```

## les cas ci dessus , calculés préalablement, ont donné les résultats suivants:

## Emsemble E50 complet

[1] "cor. pivot-cible"  "0.6482"
[1] "Ecart-type predictif" "2.8048"    
[1] "Distribution PIT"
      [,1]      [,2]         [,3]  
 [1,] "classes" "frequences" "Unif"
 [2,] "0"       "38"         "28.4"
 [3,] "0.1"     "26"         "28.4"
 [4,] "0.2"     "20"         "28.4"
 [5,] "0.3"     "22"         "28.4"
 [6,] "0.4"     "27"         "28.4"
 [7,] "0.5"     "28"         "28.4"
 [8,] "0.6"     "29"         "28.4"
 [9,] "0.7"     "22"         "28.4"
[10,] "0.8"     "44"         "28.4"
[11,] "0.9"     "28"         "28.4"

Nous avons aussi reporté ci après le résultat de la validation(fitvalid) du modèle de régression complet E50 sur l'apprentissage (où les tests de modèles par fittest sont acceptables):

V1                V2             V3
CRPS_IGN	        1.5913	       2.4485		
BRIER.B_BW	      1.1774	       2.2955	
BRIERW.OPT_SYM.	  0.3426	       0.5633		
CORR_mult	        0.6482	       1.2645	
N0_N	284	284

Certes le CRPS est moins bon mais on notera surtout la correlation multiple 0.648 certes plus grande que les correlations cible-membres individuels, toutes voisines de 0.5 mais sans comparaison avec le résultats du prédicteur unique "moyenne", soit 0.92.

## 3 predicteurs: Xbar et 2 quantiles extrèmes (+- 2*écart-types)

Ce procédé est une façon de mobiliser la dispersion des ensembles
On obtient:
 "cor. pivots-cible"  "0.9222" au lieu de 0.9200 avec la seule moyenne.
 "Ecart-type predictif" "1.4243" au lieu de 1.4429 avec la seule moyenne

V1                V2             V3
CRPS_IGN	        0.8058	       1.7709		
BRIER.B_BW	      1.2570         2.7780		
BRIERW.OPT_SYM.	  0.1611	       0.2501		
CORR_mult	        0.9222	       0

On notera que le CRPS y atteint sa valeur minimale 0.806 (au maximum 1.59 pour E50) alors que toud les autres modèles sont proches de 0.90.

## 1 prédicteur unique: moyenne Xbar studentisée

"cor. pivot-cible"     "0.8611"
"Ecart-type predictif" "1.8727"

V1                V2             V3
CRPS_IGN	        1.0494         2.0446		
BRIER.B_BW	      1.2181         2.4848	
BRIERW.OPT_SYM.	  0.2435         0.3871		
CORR_mult	        0.8611	         -

Ces valeurs peuvent être comparées au tableau identique pour la série de validation 2012, résultats comparés qui sont assez stables alors que les tailles de série sont, rappelons le 284 et 71 (rapport 1/4)

CRPS_IGN	        0.8867	       1.8796		
BRIER.B_BW	      1.2838	       2.7009		
BRIERW.OPT_SYM.	  0.2114	       0.3325		
CORR_mult	        0.8844	        -

### Le chunk ci dessous est la suite tests + validation du chunk précédent sur les modèles complémentaires dont  certains résultats avaient été calculés préalablement

```{r}
Yrp<-(y-mvp)/sdvp
dfXp<-dnorm(Yrp,0,1)
TTaXC<-fittest(y,mvp,sdvp,N0)
X<-y
ggplot(as.data.frame(X), aes(x = X)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill ="white") +
stat_function(fun = dnorm, args = list(mean = MEy, sd = Sdy),col="red",lwd=2)
dgP0 <- TTaXC[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
print("Distribution PIT")
print(matrix(c("classes",seq(0,0.9,0.1),"frequences",dgP0[[2]],"Unif",rep(N/10,10)),11,3))
TTtabXC<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm","Xbar_SD","tailles",TTaXC[[2]]),6,3))
#----------
W<-c(rep(1,9),5)
vcep<-fitvalid(y,mvp, sdvp,N0,W,0)
TtabXCv<-as.data.frame(matrix(c("CRPS_IGN","BRIER.B_BW","BRIERW.OPT_SYM.","CORR_mult","N0_N",vcep[[1]]),5,3))
PR0W<-vcep[[2]]
N<-length(X)
dg<-as.data.frame(matrix(c(X,mvp,sdvp,PR0W),length(X),4))
dg%>% ggplot(aes(x=1:N))+geom_ribbon(aes(ymin=mvp-1.64*sdvp,ymax=mvp+1.64*sdvp),color="black")+ geom_path(aes(y=X))+geom_point(aes(y=X),color="red", lwd=2)+ggtitle("cible_rouge et Echangeable1_90%")
kable(TTtabXC)
kable(TtabXCv)
```

# Modèle BMA




```{r}
library(ensembleBMA)
library(chron)
N<-length(apprentissage0[,1])
y<-apprentissage0[seq(1,N,3),1]
#Dates<-apprentissage[,4]
x<-Eas[seq(1,N,3),]
obs<-y
N<-length(y)
datacep<-ensembleData(x, observations = obs, forecastHour=12,initializationTime = "00")
DATES<-ymdhTOjul(c("2012050112","2012050212"),origin=c(month=1,day=1,year=2012))
CC<-dateCheck(c("20120501", "20120502"))
cond<-if_else(CC==TRUE,1,0)
modBma<-fitBMAnormal(datacep, control = controlBMAnormal(), exchangeable = c(1:50))
Bcoef<-modBma[[1]]
sdm<-modBma[[2]]
ponds<-modBma[[3]]
# Paramètres prédictifs (indice p) -------
X0<-t(x)
C<-sdm
ff<-matrix(NA,50,length(y))
for(k in 1:50){
ff[k,]<-Bcoef[1,k]+Bcoef[2,k]*X0[k,] 
}
PONDS<-matrix(ponds,50,length(y))
mvp<-apply(ponds*ff,2,"sum")
sdvp<-rep(C,N)
Yrp<-(y-mvp)/sdvp
Gvp<-pnorm(y,mvp,sdvp)
HYrp <-hist(Yrp,50,plot=FALSE)
dy<-HYrp[[3]]
ay<-HYrp[[4]]
layout(matrix(c(1,2,3,4),2,2))
par(bg="grey90")
plot(ay,dy,"h",main="histogramme de la cible")
lines(ay,dnorm(ay,MEy,Sdy),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
Hp<-hist(Yp,50,plot=FALSE)
dp<-Hp[[3]]
ap<-Hp[[4]]
plot(ap,dp,"h",main="histogramme du Predictif")
lines(ap,dnorm(ap,mean(Yp),sd(Yp)),"l",col="red",lwd=3)
grid(nx=NULL,ny=NULL,lty=6)
plot(Yp,y,"p",main="regression cible-predicteur")
lines(Yp,Yp,"l",col="red")
grid(nx=NULL,ny=NULL,lty=6)
CEbma<-matrix(c("correl",cor(y,Yp),"Ecart-type residu",sd(y-Yp)),2,2)
kable(CEbma)
```

## COMMENTAIRES

 
"no dates specified[1] " indique la console. Bien entendu ce rapport traite des propriétés statistiques sur échantillons. En dehors de calculs de critères sur échantillons, nous n'avons pas étudié le cas d'évènements particuliers (souci pragmatique du package BMA)

**On notera le  coefficient de correlation 0.86 avec la cible cependant inférieur au resultat du prédicteur unique qu'est la moyenne Xbar (0.92)**

Ce résultat suppose l'échangeabilité des membres (sans échangeabilité mentionnée le résultat BMA s'est avéré identique =0.86 pour Vouglans)

Ces résultats (confirmés par les tests ci après) illustrent une propriété statistique très importante. Dans leur méthode BMA, Raftery et al. n'utilisent l'échangeabilité que comme impliquant l'identité des paramètres de leur modèle. Mais l'échangeabilité est une hypothèse beaucoup plus forte impliquant l'existence de pivots ou statistiques résumantes comme Xbar et donc de modèles plus efficaces. Ceci est contenue dans les conséquences du théorème de représentation de deFinetti, Hewitt, Savage que beaucoup de statisticiens eminents modernes ont bien tord de négliger.

## Tests et Validation sur BMA.

```{r}
Tbma<-(y-mvp)/sdvp
N<-length(Tbma)
dfTbma<-dnorm(Tbma,0,1)
# Inference et tests ------
TTabma<-fittest(y,mvp,sdvp,N0)
ggplot(as.data.frame(Tbma), aes(x = Tbma)) + 
    geom_histogram(aes(y =..density..),
                    colour = "black", fill = "white") +
stat_function(fun = dnorm, args = list(mean = 0, sd = 1),col="red",lwd=2)
dgP0 <- TTabma[[1]]
dgP <- with(dgP0, data.frame(dgP0[[4]],dgP0[[2]]))
ggplot(dgP)+ geom_col(aes(x=dgP0[[4]],y=dgP0[[2]])) +
ggtitle("Diagramme PIT") +
  xlab("classes") + ylab("frequences")+ geom_hline(yintercept=mean(dgP0[[2]]), color = "red",lwd=5)
print("Distribution PIT")
print(matrix(c("classes",seq(0,0.9,0.1),"frequences",dgP0[[2]],"Unif",rep(N/10,10)),11,3))
TTtabbma<-as.data.frame(matrix(c("CRAMERVM","CHI2_probab","CHI2_credib","logRbayesNorm","Xbar_SD","tailles",TTabma[[2]]),6,3))
#----------Validation
N0<-length(Tds)
W<-c(rep(1,9),5)
vbma<-fitvalid(X,mvp, sdvp,N0,W,0)
Ttabbmav<-as.data.frame(matrix(c("CRPS_IGN","BRIER.B_BW","BRIERW.OPT_SYM","CORR_mult",
"tailles",vbma[[1]]),5,3))
PR0W<-vbma[[2]]
N<-length(X)
dg<-as.data.frame(matrix(c(X,mvp,sdvp,PR0W),length(X),4))
dg%>% ggplot(aes(x=1:N))+geom_ribbon(aes(ymin=mvp-1.64*sdvp,ymax=mvp+1.64*sdvp),color="black")+ geom_path(aes(y=X))+geom_point(aes(y=X),color="red", lwd=2)+ggtitle("valeur et BMA")
kable(TTtabbma)
kable(Ttabbmav)

```

En commentaires on constate que tous les tests statistiques sont convenables mais il faut noter la forte valeur du CRPS (calculée sur les 4 ans d'apprentissage, rappelons le) =1.7238.
C'est la valeur la plus forte de tous nos résultats. Rappelons que ces calculs sont faits selon le package BMA développé par Raftery et son équipe et montrerait donc que, sur notre exemple de Vouglans, le modèle BMA est le moins bon de tous les modèles inventoriés.
Mais cela ne remet pas en cause notre opinion assez réservée concernant le peu de sensibilité du CRPS.

### ---------


# Eléments de conclusions temporaires

Dans ces conclusions, je souhaiterais insister sur l'importance de s'appuyer sur la cohérence des vrais principes de statistique mathématique, notamment dans les tâches suivantes:

1- construire de vraies distributions prédictives issues de la loi conjointe [cible, information-membres] nécessaire si on déterminer la distribution conditionnelle_predictive: [cible|information]. Avec cette perspective on s'aperçoit que la bataille frequentiste-bayesien ne porte que sur l'interprétation des mêmes concepts dans les deux cas.

2- utiliser de façon cohérente ces principes statistiques du problème que tous les specialistes s'accordent à poser: construire la prevision comme une "vraie distribution de probabilité conditionnelle". C'est ainsi que si on suppose l'échangeabilité des ensembles de membre, encore faut il l'utiliser dans ** toutes les conséquences de son application**.

3- La théorie de la Decision Statistique (TDS) fournit un cadre d'analyse idéal pour traiter **le problème de la Prévision Probabiliste avec ses Consequences** La considération du CRPS et du Brier ont été un progrès notable dans cette voie. C'est leur (seul usage) qui nous semble en question. Revenir vers de vrais tests et validations statistique nous semble une tâche utile sinon nécessaire. Nous ne prétendons pas les quelques tests et critères simples utilisés dans les fonctions fittest et fitvalid sont suffisants; ils ont seulement le mérite d'être possibles.

4- D'autres bénéfices sont aussi tirés de la BFS. les auteurs de "post-traitements" auraient eu intérèt à considérer "l'admissibité" de leur méthodes au regard de la propriété générale de dominance des modèles bayesiens (considérés en subjectiviste comme en frequentiste). Cela est essentiel à la mise en perspective des méthodes de membres compétitifs ( BMA, best members, très à la mode dans le monde appliqué)

A voir avec Eric!!!


# Discussions

On dispose d'autres données de températures du même type, en France : le Drac au Sautet et le Buech au Chambon, ainsi qu'au Québec pour cinq bassins versants du complexe Manicouagan : Manic 3, Petit-Lac-Manicouagan,  Manic 5, Manic 2 et Toulnustouc.


